{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnzRlaQaW6y1"
   },
   "source": [
    "In this homework, you will write a python implementation of logistic regression. You will test it on two datasets. \n",
    "First we import some libraries that we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Szla9qyoPuqg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0byO4vq0Xcxz"
   },
   "source": [
    "We define some functions involved. Use the formulations that avoid overflows.  \n",
    "1. sigmoid function sigmoid(t)\n",
    "2. log of sigmoid(t), called log_sig(t)\n",
    "3. log of 1-sigmoid = 1/(1+e^t), called log_one_sig(t)\n",
    "4. cross-entropy loss function given the inputs of label y and prediction y_hat = sigmoid(z), where y, y_hat, and z are vectors of dimension N. (N = # of data points.) You should implement this function with z, rather than y_hat, as the input; namely, the loss function should be\n",
    "\n",
    "    loss = -y log(sigmoid(z)) - (1-y) log (1-sigmoid(z)) \n",
    "\n",
    "  where log(sigmoid(z)) and log (1-sigmoid(z)) should be computed by the functions log_sig(z) and log_one_sig(z) in parts 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kuzmD54GT9yb"
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "      return 1/(1+np.exp(-t))\n",
    "\n",
    "def custom_loss(y, z):\n",
    "    return ((-y*log_sig(z)) - ((1-y)*log_one_sig(z)))\n",
    "\n",
    "def log_sig(t):\n",
    "      return np.log(sigmoid(t))\n",
    "\n",
    "def log_one_sig(t):\n",
    "      return np.log(1-sigmoid(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLulJqXcbEpw"
   },
   "source": [
    "Define the model output z=w^T x + b, or z = x^Tw + B, given the data input X (an N-by-n array containing N data points) and the model parameters w (n-dimensional weigth vector) and b (bias).\n",
    "\n",
    "Note that mathematically it's easier to write the data matrix as an n-by-N matrix, with each column being a data point. In python, the data is more commonly represented as as an N-by-n array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "eI9PNMZnhy0d"
   },
   "outputs": [],
   "source": [
    "def model(w,b,X):\n",
    "  # using X as Nxn\n",
    "  print(f'In model, X: {X.shape}, b: {b}, w: {w.shape}')\n",
    "  return (X @ w)+b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv_xi0ajaEEY"
   },
   "source": [
    "Define the function that computes the gradient of the cross-entropy loss given the label y (N-vector), the model prediction y_hat = sigmoid(z) (N-vector), and the dataset X (an n-by-N or N-by-n array). It's probably easier to return the gradients with respect w and b separately, which can be used to update w and b later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "I8KJF8lrZlFi"
   },
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "  # Using X as Nxn\n",
    "  print(f'grad: y shape: {y.shape}, X shape: {X.shape}')\n",
    "  return (np.transpose(X) @ (y_hat - y))/X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgqML9T2cOqd"
   },
   "source": [
    "Write the function that minimizes the loss (i.e. training) by the gradient descent algorithm using a fixed number of iteration (*iter*) and learning rate (*lr*). Your function should take *iter* and *lr* as well as the initial weight w, initial bias b, the input data X and the label y as the inputs. It produces new w and b as output. Also compute the loss value at each iteration and output the sequence of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "id": "6bIdE16li086"
   },
   "outputs": [],
   "source": [
    "def train(w, b, X, y, iter, lr):\n",
    "  print(f'>> {X.shape}')\n",
    "  losslist=list()\n",
    "  print('>>',X.shape)\n",
    "  for k in range(iter):\n",
    "    z = model(w, b, X)\n",
    "    y_hat = sigmoid(z)\n",
    "    grad = gradients(X, y, y_hat)\n",
    "    print(f'gradient shape: {grad.shape}')\n",
    "    w = w - (lr * grad)\n",
    "    print(f'y_hat: {y_hat.shape}, y: {y.shape}')\n",
    "#     b = b - (lr * (y_hat - y)[0])\n",
    "    b = np.mean((b*np.ones(y_hat.shape)) - (lr * (y_hat - y)))\n",
    "    myloss = custom_loss(y, y_hat)\n",
    "    losslist.append(np.mean(myloss))\n",
    "    print(f'Iter: {k} Loss: {losslist[-1]}')\n",
    "  w_hat = np.transpose(w_hat)[0]\n",
    "  return w_hat[1:], w_hat[0], losslist\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGC-EjrzeHyU"
   },
   "source": [
    "1. Write the function that uses a trained model to produce class prediction (0 or 1) for an input dataset X, i.e. turn the model output z = model(w,b,X) into predicted label y_label (N-vector of 0 or 1). \n",
    "2. For an input dataset X with a known label y (e.g. a training or testing dataset) and a predicted label y_label, compute the accuracy of prediction (i.e. # correct predictions/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "HChwCsuWf07D"
   },
   "outputs": [],
   "source": [
    "def predict(z):\n",
    "  ypred = sigmoid(z)\n",
    "  ypred[ypred<=0.5]=0\n",
    "  ypred[ypred>0.5]=1\n",
    "  ypred = ypred.astype(int)\n",
    "  ypred = np.squeeze(ypred)\n",
    "  # print(f'In pred, {ypred.shape}')\n",
    "  return ypred\n",
    "\n",
    "def accuracy(y, y_label):\n",
    "  diff_bool = (y == y_label)\n",
    "  diff_true = diff_bool[diff_bool==True]\n",
    "  total_sample = len(diff_bool)\n",
    "  return (len(diff_true)/total_sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icfCmavagcp5"
   },
   "source": [
    "We are ready to test your programs on some datasets. First, we use a synthetic dataset generated using [scikit-learn](https://scikit-learn.org/stable/datasets.html) package. We generate a dataset for training and simultaneously a dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "EXJOlxH2nYw3",
    "outputId": "a2ffea0e-e5d7-4904-81d3-3c65d9dac67d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc510962d70>]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X_train, y_train = make_moons(n_samples=500, noise=0.1)\n",
    "X_test, y_test = make_moons(n_samples=1000, noise=0.1)\n",
    "\n",
    "print(X_train.shape)\n",
    "plt.figure()\n",
    "plt.plot(X_train[:, 0][y_train==0], X_train[:, 1][y_train==0], \"g^\")\n",
    "plt.plot(X_train[:, 0][y_train==1], X_train[:, 1][y_train==1], \"bs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2_uUM_Zufoz"
   },
   "source": [
    "Here is another toy test example you may try but not part of homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "EJbVzPfLdOvC",
    "outputId": "91844d24-7e83-418c-91af-70f6c41b1272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc5109c2380>]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X_train, y_train = make_classification(n_samples=1000, n_features=4)\n",
    "X_test=X_train[500:,]\n",
    "y_test=y_train[500:,]\n",
    "X_train=X_train[:500,]\n",
    "y_train=y_train[:500,]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X_train[:, 0][y_train==0], X_train[:, 1][y_train==0], \"g^\")\n",
    "plt.plot(X_train[:, 0][y_train==1], X_train[:, 1][y_train==1], \"bs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMm__k_AjOFp"
   },
   "source": [
    "We now train the model using (X_train, y_train). We initialize weight as a random vector, and b=0. We plot the loss convergence history. You should get the loss down to about 0.2.\n",
    "We compute the prediction accuracy on (X_train, y_train). You should get an accuracy in the 80s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "mi868jT_mpnq",
    "outputId": "f6d75f4c-6a30-41c5-fceb-eb621f7fd69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(500, 4)\n",
      "(500, 1)\n",
      ">> (500, 4)\n",
      ">> (500, 4)\n",
      "In model, X: (500, 4), b: 0, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 0 Loss: 0.7080857956362961\n",
      "In model, X: (500, 4), b: 0.0009168099587221059, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 1 Loss: 0.7014104799107681\n",
      "In model, X: (500, 4), b: 0.001953640804545477, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 2 Loss: 0.69498584255163\n",
      "In model, X: (500, 4), b: 0.003108250672714767, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 3 Loss: 0.6888472823644091\n",
      "In model, X: (500, 4), b: 0.0043763300250973915, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 4 Loss: 0.6830187551688212\n",
      "In model, X: (500, 4), b: 0.005751794715865115, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 5 Loss: 0.6775135895361191\n",
      "In model, X: (500, 4), b: 0.007227174491174931, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 6 Loss: 0.6723359309790957\n",
      "In model, X: (500, 4), b: 0.008794033556641576, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 7 Loss: 0.6674824818079933\n",
      "In model, X: (500, 4), b: 0.010443374042325435, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 8 Loss: 0.66294427385025\n",
      "In model, X: (500, 4), b: 0.01216599055394556, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 9 Loss: 0.6587082995918779\n",
      "In model, X: (500, 4), b: 0.013952759948208023, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 10 Loss: 0.6547589082684021\n",
      "In model, X: (500, 4), b: 0.01579486270384633, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 11 Loss: 0.6510789349074739\n",
      "In model, X: (500, 4), b: 0.017683940272304383, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 12 Loss: 0.6476505702857245\n",
      "In model, X: (500, 4), b: 0.01961219713160676, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 13 Loss: 0.6444560015895686\n",
      "In model, X: (500, 4), b: 0.02157245789547563, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 14 Loss: 0.6414778624148827\n",
      "In model, X: (500, 4), b: 0.02355818971508939, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 15 Loss: 0.6386995314629341\n",
      "In model, X: (500, 4), b: 0.02556349913631211, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 16 Loss: 0.6361053156302499\n",
      "In model, X: (500, 4), b: 0.02758311109161071, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 17 Loss: 0.6336805476677873\n",
      "In model, X: (500, 4), b: 0.02961233615718861, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 18 Loss: 0.6314116227129887\n",
      "In model, X: (500, 4), b: 0.03164703078039789, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 19 Loss: 0.6292859925756636\n",
      "In model, X: (500, 4), b: 0.033683553964231706, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 20 Loss: 0.6272921320279058\n",
      "In model, X: (500, 4), b: 0.035718722905490746, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 21 Loss: 0.6254194875885409\n",
      "In model, X: (500, 4), b: 0.037749769307819335, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 22 Loss: 0.6236584163470615\n",
      "In model, X: (500, 4), b: 0.03977429750152991, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 23 Loss: 0.622000120125816\n",
      "In model, X: (500, 4), b: 0.04179024506580488, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 24 Loss: 0.6204365786031416\n",
      "In model, X: (500, 4), b: 0.0437958463336449, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 25 Loss: 0.6189604837925932\n",
      "In model, X: (500, 4), b: 0.04578959893796706, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 26 Loss: 0.6175651773896985\n",
      "In model, X: (500, 4), b: 0.04777023340549814, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 27 Loss: 0.6162445918723017\n",
      "In model, X: (500, 4), b: 0.04973668570518713, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 28 Loss: 0.6149931958061756\n",
      "In model, X: (500, 4), b: 0.0516880725955301, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 29 Loss: 0.6138059435124265\n",
      "In model, X: (500, 4), b: 0.053623669579634735, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 30 Loss: 0.6126782290582604\n",
      "In model, X: (500, 4), b: 0.05554289125996563, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 31 Loss: 0.6116058444089181\n",
      "In model, X: (500, 4), b: 0.057445273880552164, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 32 Loss: 0.6105849415047555\n",
      "In model, X: (500, 4), b: 0.05933045984868373, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 33 Loss: 0.6096119979880561\n",
      "In model, X: (500, 4), b: 0.06119818403766333, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 34 Loss: 0.6086837862881439\n",
      "In model, X: (500, 4), b: 0.06304826168484916, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 35 Loss: 0.6077973457727381\n",
      "In model, X: (500, 4), b: 0.06488057771346226, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 36 Loss: 0.6069499576827294\n",
      "In model, X: (500, 4), b: 0.06669507732143948, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 37 Loss: 0.6061391225827149\n",
      "In model, X: (500, 4), b: 0.06849175769527746, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 38 Loss: 0.6053625400780546\n",
      "In model, X: (500, 4), b: 0.07027066072090644, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 39 Loss: 0.6046180905690794\n",
      "In model, X: (500, 4), b: 0.07203186657689029, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 40 Loss: 0.6039038188331881\n",
      "In model, X: (500, 4), b: 0.07377548810752874, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 41 Loss: 0.603217919245157\n",
      "In model, X: (500, 4), b: 0.07550166588468353, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 42 Loss: 0.6025587224645805\n",
      "In model, X: (500, 4), b: 0.07721056387735752, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 43 Loss: 0.6019246834366889\n",
      "In model, X: (500, 4), b: 0.0789023656572594, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 44 Loss: 0.601314370568761\n",
      "In model, X: (500, 4), b: 0.08057727107684079, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 45 Loss: 0.6007264559588887\n",
      "In model, X: (500, 4), b: 0.08223549336366426, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 46 Loss: 0.6001597065670399\n",
      "In model, X: (500, 4), b: 0.08387725658152272, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 47 Loss: 0.5996129762302124\n",
      "In model, X: (500, 4), b: 0.08550279341455638, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 48 Loss: 0.5990851984341314\n",
      "In model, X: (500, 4), b: 0.08711234323577535, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 49 Loss: 0.5985753797634391\n",
      "In model, X: (500, 4), b: 0.08870615042596063, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 50 Loss: 0.5980825939608155\n",
      "In model, X: (500, 4), b: 0.09028446291295002, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 51 Loss: 0.5976059765330307\n",
      "In model, X: (500, 4), b: 0.09184753090487385, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 52 Loss: 0.5971447198486363\n",
      "In model, X: (500, 4), b: 0.09339560579404432, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 53 Loss: 0.5966980686779862\n",
      "In model, X: (500, 4), b: 0.09492893921096839, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 54 Loss: 0.5962653161315741\n",
      "In model, X: (500, 4), b: 0.09644778221039076, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 55 Loss: 0.595845799957385\n",
      "In model, X: (500, 4), b: 0.09795238457342068, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 56 Loss: 0.5954388991621412\n",
      "In model, X: (500, 4), b: 0.09944299421168588, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 57 Loss: 0.5950440309250388\n",
      "In model, X: (500, 4), b: 0.10091985666112234, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 58 Loss: 0.594660647775864\n",
      "In model, X: (500, 4), b: 0.10238321465447413, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 59 Loss: 0.594288235012314\n",
      "In model, X: (500, 4), b: 0.1038333077628695, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 60 Loss: 0.5939263083339545\n",
      "In model, X: (500, 4), b: 0.10527037209797627, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 61 Loss: 0.5935744116725635\n",
      "In model, X: (500, 4), b: 0.10669464006724223, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 62 Loss: 0.5932321152006733\n",
      "In model, X: (500, 4), b: 0.10810634017560972, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 63 Loss: 0.5928990135019675\n",
      "In model, X: (500, 4), b: 0.10950569686787158, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 64 Loss: 0.5925747238888224\n",
      "In model, X: (500, 4), b: 0.11089293040652325, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 65 Loss: 0.5922588848537521\n",
      "In model, X: (500, 4), b: 0.1122682567805704, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 66 Loss: 0.5919511546428169\n",
      "In model, X: (500, 4), b: 0.11363188764128679, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 67 Loss: 0.5916512099402255\n",
      "In model, X: (500, 4), b: 0.11498403026138802, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 68 Loss: 0.5913587446544063\n",
      "In model, X: (500, 4), b: 0.11632488751450369, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 69 Loss: 0.5910734687967545\n",
      "In model, X: (500, 4), b: 0.11765465787219785, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 70 Loss: 0.5907951074451042\n",
      "In model, X: (500, 4), b: 0.11897353541611304, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 71 Loss: 0.5905233997847211\n",
      "In model, X: (500, 4), b: 0.12028170986309965, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 72 Loss: 0.5902580982202903\n",
      "In model, X: (500, 4), b: 0.1215793666014466, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 73 Loss: 0.5899989675529758\n",
      "In model, X: (500, 4), b: 0.1228666867365535, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 74 Loss: 0.5897457842171767\n",
      "In model, X: (500, 4), b: 0.12414384714458299, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 75 Loss: 0.5894983355720927\n",
      "In model, X: (500, 4), b: 0.12541102053280712, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 76 Loss: 0.5892564192436541\n",
      "In model, X: (500, 4), b: 0.12666837550551743, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 77 Loss: 0.5890198425127713\n",
      "In model, X: (500, 4), b: 0.1279160766345055, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 78 Loss: 0.5887884217462165\n",
      "In model, X: (500, 4), b: 0.1291542845332419, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 79 Loss: 0.5885619818667759\n",
      "In model, X: (500, 4), b: 0.1303831559339903, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 80 Loss: 0.5883403558596033\n",
      "In model, X: (500, 4), b: 0.13160284376718726, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 81 Loss: 0.5881233843119738\n",
      "In model, X: (500, 4), b: 0.13281349724250344, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 82 Loss: 0.5879109149838742\n",
      "In model, X: (500, 4), b: 0.13401526193107655, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 83 Loss: 0.5877028024070864\n",
      "In model, X: (500, 4), b: 0.1352082798484717, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 84 Loss: 0.5874989075106175\n",
      "In model, X: (500, 4), b: 0.1363926895379844, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 85 Loss: 0.587299097270508\n",
      "In model, X: (500, 4), b: 0.13756862615395146, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 86 Loss: 0.5871032443822181\n",
      "In model, X: (500, 4), b: 0.13873622154478302, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 87 Loss: 0.586911226953931\n",
      "In model, X: (500, 4), b: 0.13989560433546655, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 88 Loss: 0.5867229282192604\n",
      "In model, X: (500, 4), b: 0.1410469000093322, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 89 Loss: 0.5865382362679544\n",
      "In model, X: (500, 4), b: 0.14219023098889824, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 90 Loss: 0.5863570437933208\n",
      "In model, X: (500, 4), b: 0.1433257167156443, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 91 Loss: 0.586179247855183\n",
      "In model, X: (500, 4), b: 0.14445347372858444, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 92 Loss: 0.5860047496572809\n",
      "In model, X: (500, 4), b: 0.14557361574153344, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 93 Loss: 0.5858334543381083\n",
      "In model, X: (500, 4), b: 0.14668625371897928, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 94 Loss: 0.5856652707742643\n",
      "In model, X: (500, 4), b: 0.14779149595049104, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 95 Loss: 0.5855001113954592\n",
      "In model, X: (500, 4), b: 0.14888944812360633, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 96 Loss: 0.5853378920103879\n",
      "In model, X: (500, 4), b: 0.14998021339515535, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 97 Loss: 0.5851785316427375\n",
      "In model, X: (500, 4), b: 0.15106389246099022, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 98 Loss: 0.5850219523766561\n",
      "In model, X: (500, 4), b: 0.15214058362409735, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 99 Loss: 0.5848680792110565\n",
      "In model, X: (500, 4), b: 0.15321038286108002, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 100 Loss: 0.5847168399221745\n",
      "In model, X: (500, 4), b: 0.15427338388700532, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 101 Loss: 0.5845681649338478\n",
      "In model, X: (500, 4), b: 0.15532967821861668, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 102 Loss: 0.5844219871950163\n",
      "In model, X: (500, 4), b: 0.15637935523591784, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 103 Loss: 0.5842782420639818\n",
      "In model, X: (500, 4), b: 0.15742250224213994, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 104 Loss: 0.5841368671989998\n",
      "In model, X: (500, 4), b: 0.1584592045221072, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 105 Loss: 0.5839978024548045\n",
      "In model, X: (500, 4), b: 0.1594895453990199, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 106 Loss: 0.5838609897846966\n",
      "In model, X: (500, 4), b: 0.16051360628967665, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 107 Loss: 0.5837263731478505\n",
      "In model, X: (500, 4), b: 0.16153146675816038, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 108 Loss: 0.5835938984215204\n",
      "In model, X: (500, 4), b: 0.16254320456801472, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 109 Loss: 0.5834635133178461\n",
      "In model, X: (500, 4), b: 0.1635488957329387, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 110 Loss: 0.583335167304982\n",
      "In model, X: (500, 4), b: 0.16454861456602948, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 111 Loss: 0.5832088115322898\n",
      "In model, X: (500, 4), b: 0.16554243372760374, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 112 Loss: 0.5830843987593524\n",
      "In model, X: (500, 4), b: 0.16653042427162934, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 113 Loss: 0.5829618832885854\n",
      "In model, X: (500, 4), b: 0.1675126556907991, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 114 Loss: 0.5828412209012348\n",
      "In model, X: (500, 4), b: 0.16848919596027964, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 115 Loss: 0.5827223687965625\n",
      "In model, X: (500, 4), b: 0.16946011158016733, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 116 Loss: 0.5826052855340396\n",
      "In model, X: (500, 4), b: 0.17042546761668512, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 117 Loss: 0.5824899309783734\n",
      "In model, X: (500, 4), b: 0.17138532774215207, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 118 Loss: 0.5823762662472058\n",
      "In model, X: (500, 4), b: 0.17233975427375908, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 119 Loss: 0.5822642536613366\n",
      "In model, X: (500, 4), b: 0.17328880821118275, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 120 Loss: 0.5821538566973269\n",
      "In model, X: (500, 4), b: 0.17423254927306958, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 121 Loss: 0.5820450399423528\n",
      "In model, X: (500, 4), b: 0.17517103593242234, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 122 Loss: 0.5819377690511853\n",
      "In model, X: (500, 4), b: 0.1761043254509195, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 123 Loss: 0.5818320107051795\n",
      "In model, X: (500, 4), b: 0.17703247391219892, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 124 Loss: 0.5817277325731641\n",
      "In model, X: (500, 4), b: 0.17795553625413565, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 125 Loss: 0.5816249032741305\n",
      "In model, X: (500, 4), b: 0.17887356630014353, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 126 Loss: 0.5815234923416238\n",
      "In model, X: (500, 4), b: 0.17978661678952965, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 127 Loss: 0.5814234701897462\n",
      "In model, X: (500, 4), b: 0.18069473940692996, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 128 Loss: 0.5813248080806868\n",
      "In model, X: (500, 4), b: 0.18159798481085385, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 129 Loss: 0.5812274780937006\n",
      "In model, X: (500, 4), b: 0.1824964026613648, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 130 Loss: 0.5811314530954587\n",
      "In model, X: (500, 4), b: 0.18339004164692316, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 131 Loss: 0.5810367067117008\n",
      "In model, X: (500, 4), b: 0.18427894951041723, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 132 Loss: 0.5809432133001228\n",
      "In model, X: (500, 4), b: 0.1851631730744076, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 133 Loss: 0.5808509479244373\n",
      "In model, X: (500, 4), b: 0.18604275826560898, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 134 Loss: 0.5807598863295463\n",
      "In model, X: (500, 4), b: 0.18691775013863338, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 135 Loss: 0.5806700049177739\n",
      "In model, X: (500, 4), b: 0.18778819289901752, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 136 Loss: 0.5805812807261023\n",
      "In model, X: (500, 4), b: 0.18865412992555736, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 137 Loss: 0.5804936914043631\n",
      "In model, X: (500, 4), b: 0.18951560379197088, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 138 Loss: 0.5804072151943409\n",
      "In model, X: (500, 4), b: 0.1903726562879107, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 139 Loss: 0.5803218309097351\n",
      "In model, X: (500, 4), b: 0.19122532843934686, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 140 Loss: 0.5802375179169521\n",
      "In model, X: (500, 4), b: 0.19207366052833982, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 141 Loss: 0.5801542561166741\n",
      "In model, X: (500, 4), b: 0.19291769211222248, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 142 Loss: 0.5800720259261782\n",
      "In model, X: (500, 4), b: 0.1937574620422108, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 143 Loss: 0.5799908082623647\n",
      "In model, X: (500, 4), b: 0.19459300848146024, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 144 Loss: 0.5799105845254623\n",
      "In model, X: (500, 4), b: 0.19542436892258597, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 145 Loss: 0.5798313365833802\n",
      "In model, X: (500, 4), b: 0.19625158020466413, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 146 Loss: 0.5797530467566744\n",
      "In model, X: (500, 4), b: 0.19707467852973, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 147 Loss: 0.5796756978041032\n",
      "In model, X: (500, 4), b: 0.19789369947878982, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 148 Loss: 0.5795992729087414\n",
      "In model, X: (500, 4), b: 0.1987086780273607, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 149 Loss: 0.5795237556646302\n",
      "In model, X: (500, 4), b: 0.1995196485605545, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 150 Loss: 0.5794491300639396\n",
      "In model, X: (500, 4), b: 0.2003266448877199, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 151 Loss: 0.5793753804846153\n",
      "In model, X: (500, 4), b: 0.20112970025665605, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 152 Loss: 0.5793024916784957\n",
      "In model, X: (500, 4), b: 0.20192884736741248, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 153 Loss: 0.5792304487598712\n",
      "In model, X: (500, 4), b: 0.2027241183856873, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 154 Loss: 0.5791592371944718\n",
      "In model, X: (500, 4), b: 0.20351554495583685, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 155 Loss: 0.5790888427888615\n",
      "In model, X: (500, 4), b: 0.20430315821350956, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 156 Loss: 0.5790192516802213\n",
      "In model, X: (500, 4), b: 0.20508698879791468, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 157 Loss: 0.5789504503265064\n",
      "In model, X: (500, 4), b: 0.2058670668637386, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 158 Loss: 0.5788824254969605\n",
      "In model, X: (500, 4), b: 0.20664342209271916, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 159 Loss: 0.5788151642629698\n",
      "In model, X: (500, 4), b: 0.20741608370488882, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 160 Loss: 0.5787486539892476\n",
      "In model, X: (500, 4), b: 0.20818508046949727, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 161 Loss: 0.5786828823253286\n",
      "In model, X: (500, 4), b: 0.2089504407156234, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 162 Loss: 0.5786178371973671\n",
      "In model, X: (500, 4), b: 0.20971219234248611, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 163 Loss: 0.5785535068002202\n",
      "In model, X: (500, 4), b: 0.2104703628294638, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 164 Loss: 0.5784898795898099\n",
      "In model, X: (500, 4), b: 0.21122497924583153, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 165 Loss: 0.5784269442757467\n",
      "In model, X: (500, 4), b: 0.2119760682602243, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 166 Loss: 0.5783646898142103\n",
      "In model, X: (500, 4), b: 0.2127236561498353, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 167 Loss: 0.5783031054010723\n",
      "In model, X: (500, 4), b: 0.21346776880935722, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 168 Loss: 0.5782421804652526\n",
      "In model, X: (500, 4), b: 0.21420843175967452, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 169 Loss: 0.5781819046623007\n",
      "In model, X: (500, 4), b: 0.21494567015631452, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 170 Loss: 0.5781222678681927\n",
      "In model, X: (500, 4), b: 0.21567950879766473, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 171 Loss: 0.578063260173336\n",
      "In model, X: (500, 4), b: 0.21640997213296323, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 172 Loss: 0.5780048718767707\n",
      "In model, X: (500, 4), b: 0.2171370842700696, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 173 Loss: 0.5779470934805645\n",
      "In model, X: (500, 4), b: 0.21786086898302282, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 174 Loss: 0.57788991568439\n",
      "In model, X: (500, 4), b: 0.2185813497193926, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 175 Loss: 0.5778333293802798\n",
      "In model, X: (500, 4), b: 0.2192985496074308, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 176 Loss: 0.5777773256475491\n",
      "In model, X: (500, 4), b: 0.22001249146302843, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 177 Loss: 0.5777218957478847\n",
      "In model, X: (500, 4), b: 0.22072319779648478, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 178 Loss: 0.5776670311205891\n",
      "In model, X: (500, 4), b: 0.22143069081909386, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 179 Loss: 0.5776127233779766\n",
      "In model, X: (500, 4), b: 0.22213499244955387, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 180 Loss: 0.5775589643009145\n",
      "In model, X: (500, 4), b: 0.22283612432020522, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 181 Loss: 0.5775057458345048\n",
      "In model, X: (500, 4), b: 0.2235341077831018, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 182 Loss: 0.5774530600839015\n",
      "In model, X: (500, 4), b: 0.22422896391592093, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 183 Loss: 0.5774008993102566\n",
      "In model, X: (500, 4), b: 0.22492071352771664, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 184 Loss: 0.5773492559267915\n",
      "In model, X: (500, 4), b: 0.22560937716452087, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 185 Loss: 0.577298122494991\n",
      "In model, X: (500, 4), b: 0.2262949751147973, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 186 Loss: 0.5772474917209106\n",
      "In model, X: (500, 4), b: 0.22697752741475205, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 187 Loss: 0.5771973564515979\n",
      "In model, X: (500, 4), b: 0.22765705385350563, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 188 Loss: 0.5771477096716214\n",
      "In model, X: (500, 4), b: 0.22833357397812998, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 189 Loss: 0.5770985444997045\n",
      "In model, X: (500, 4), b: 0.22900710709855485, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 190 Loss: 0.577049854185458\n",
      "In model, X: (500, 4), b: 0.2296776722923472, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 191 Loss: 0.5770016321062117\n",
      "In model, X: (500, 4), b: 0.23034528840936758, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 192 Loss: 0.5769538717639383\n",
      "In model, X: (500, 4), b: 0.2310099740763065, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 193 Loss: 0.5769065667822684\n",
      "In model, X: (500, 4), b: 0.23167174770110513, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 194 Loss: 0.5768597109035918\n",
      "In model, X: (500, 4), b: 0.2323306274772629, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 195 Loss: 0.5768132979862443\n",
      "In model, X: (500, 4), b: 0.23298663138803602, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 196 Loss: 0.5767673220017744\n",
      "In model, X: (500, 4), b: 0.23363977721052914, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 197 Loss: 0.5767217770322896\n",
      "In model, X: (500, 4), b: 0.23429008251968428, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 198 Loss: 0.5766766572678776\n",
      "In model, X: (500, 4), b: 0.2349375646921693, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 199 Loss: 0.5766319570041029\n",
      "In model, X: (500, 4), b: 0.2355822409101689, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 200 Loss: 0.5765876706395704\n",
      "In model, X: (500, 4), b: 0.2362241281650812, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 201 Loss: 0.5765437926735619\n",
      "In model, X: (500, 4), b: 0.23686324326112218, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 202 Loss: 0.5765003177037354\n",
      "In model, X: (500, 4), b: 0.2374996028188411, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 203 Loss: 0.5764572404238902\n",
      "In model, X: (500, 4), b: 0.23813322327854902, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 204 Loss: 0.5764145556217937\n",
      "In model, X: (500, 4), b: 0.23876412090366286, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 205 Loss: 0.5763722581770674\n",
      "In model, X: (500, 4), b: 0.23939231178396794, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 206 Loss: 0.5763303430591318\n",
      "In model, X: (500, 4), b: 0.24001781183880053, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 207 Loss: 0.5762888053252061\n",
      "In model, X: (500, 4), b: 0.24064063682015321, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 208 Loss: 0.5762476401183634\n",
      "In model, X: (500, 4), b: 0.24126080231570507, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 209 Loss: 0.5762068426656378\n",
      "In model, X: (500, 4), b: 0.24187832375177856, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 210 Loss: 0.5761664082761833\n",
      "In model, X: (500, 4), b: 0.24249321639622554, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 211 Loss: 0.5761263323394787\n",
      "In model, X: (500, 4), b: 0.24310549536124398, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 212 Loss: 0.5760866103235858\n",
      "In model, X: (500, 4), b: 0.24371517560612768, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 213 Loss: 0.5760472377734481\n",
      "In model, X: (500, 4), b: 0.24432227193995054, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 214 Loss: 0.5760082103092374\n",
      "In model, X: (500, 4), b: 0.2449267990241873, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 215 Loss: 0.575969523624744\n",
      "In model, X: (500, 4), b: 0.2455287713752724, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 216 Loss: 0.5759311734858061\n",
      "In model, X: (500, 4), b: 0.24612820336709912, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 217 Loss: 0.5758931557287833\n",
      "In model, X: (500, 4), b: 0.24672510923345967, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 218 Loss: 0.5758554662590677\n",
      "In model, X: (500, 4), b: 0.2473195030704288, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 219 Loss: 0.5758181010496327\n",
      "In model, X: (500, 4), b: 0.24791139883869207, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 220 Loss: 0.5757810561396209\n",
      "In model, X: (500, 4), b: 0.24850081036582014, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 221 Loss: 0.5757443276329665\n",
      "In model, X: (500, 4), b: 0.2490877513484908, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 222 Loss: 0.5757079116970518\n",
      "In model, X: (500, 4), b: 0.24967223535465996, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 223 Loss: 0.5756718045614009\n",
      "In model, X: (500, 4), b: 0.25025427582568305, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 224 Loss: 0.575636002516402\n",
      "In model, X: (500, 4), b: 0.2508338860783882, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 225 Loss: 0.5756005019120648\n",
      "In model, X: (500, 4), b: 0.2514110793071024, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 226 Loss: 0.5755652991568068\n",
      "In model, X: (500, 4), b: 0.25198586858563177, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 227 Loss: 0.5755303907162713\n",
      "In model, X: (500, 4), b: 0.25255826686919775, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 228 Loss: 0.5754957731121726\n",
      "In model, X: (500, 4), b: 0.2531282869963294, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 229 Loss: 0.5754614429211722\n",
      "In model, X: (500, 4), b: 0.2536959416907138, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 230 Loss: 0.5754273967737787\n",
      "In model, X: (500, 4), b: 0.25426124356300545, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 231 Loss: 0.5753936313532786\n",
      "In model, X: (500, 4), b: 0.2548242051125952, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 232 Loss: 0.5753601433946893\n",
      "In model, X: (500, 4), b: 0.25538483872934076, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 233 Loss: 0.5753269296837404\n",
      "In model, X: (500, 4), b: 0.255943156695259, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 234 Loss: 0.5752939870558766\n",
      "In model, X: (500, 4), b: 0.25649917118618126, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 235 Loss: 0.5752613123952869\n",
      "In model, X: (500, 4), b: 0.25705289427337263, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 236 Loss: 0.5752289026339547\n",
      "In model, X: (500, 4), b: 0.2576043379251164, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 237 Loss: 0.5751967547507324\n",
      "In model, X: (500, 4), b: 0.2581535140082637, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 238 Loss: 0.5751648657704362\n",
      "In model, X: (500, 4), b: 0.25870043428975076, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 239 Loss: 0.5751332327629629\n",
      "In model, X: (500, 4), b: 0.25924511043808296, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 240 Loss: 0.5751018528424272\n",
      "In model, X: (500, 4), b: 0.2597875540247878, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 241 Loss: 0.5750707231663191\n",
      "In model, X: (500, 4), b: 0.2603277765258366, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 242 Loss: 0.5750398409346801\n",
      "In model, X: (500, 4), b: 0.26086578932303645, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 243 Loss: 0.5750092033893001\n",
      "In model, X: (500, 4), b: 0.26140160370539267, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 244 Loss: 0.5749788078129309\n",
      "In model, X: (500, 4), b: 0.26193523087044324, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 245 Loss: 0.5749486515285185\n",
      "In model, X: (500, 4), b: 0.26246668192556477, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 246 Loss: 0.5749187318984531\n",
      "In model, X: (500, 4), b: 0.2629959678892518, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 247 Loss: 0.5748890463238354\n",
      "In model, X: (500, 4), b: 0.2635230996923693, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 248 Loss: 0.5748595922437603\n",
      "In model, X: (500, 4), b: 0.2640480881793801, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 249 Loss: 0.5748303671346161\n",
      "In model, X: (500, 4), b: 0.26457094410954607, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 250 Loss: 0.574801368509399\n",
      "In model, X: (500, 4), b: 0.26509167815810586, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 251 Loss: 0.5747725939170445\n",
      "In model, X: (500, 4), b: 0.26561030091742815, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 252 Loss: 0.5747440409417715\n",
      "In model, X: (500, 4), b: 0.26612682289814166, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 253 Loss: 0.5747157072024427\n",
      "In model, X: (500, 4), b: 0.2666412545302424, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 254 Loss: 0.5746875903519381\n",
      "In model, X: (500, 4), b: 0.2671536061641791, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 255 Loss: 0.5746596880765423\n",
      "In model, X: (500, 4), b: 0.2676638880719164, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 256 Loss: 0.5746319980953457\n",
      "In model, X: (500, 4), b: 0.2681721104479774, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 257 Loss: 0.5746045181596581\n",
      "In model, X: (500, 4), b: 0.26867828341046535, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 258 Loss: 0.5745772460524355\n",
      "In model, X: (500, 4), b: 0.26918241700206524, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 259 Loss: 0.5745501795877191\n",
      "In model, X: (500, 4), b: 0.26968452119102587, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 260 Loss: 0.5745233166100863\n",
      "In model, X: (500, 4), b: 0.2701846058721228, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 261 Loss: 0.574496654994113\n",
      "In model, X: (500, 4), b: 0.2706826808676025, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 262 Loss: 0.5744701926438488\n",
      "In model, X: (500, 4), b: 0.2711787559281082, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 263 Loss: 0.5744439274923016\n",
      "In model, X: (500, 4), b: 0.27167284073358805, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 264 Loss: 0.5744178575009341\n",
      "In model, X: (500, 4), b: 0.2721649448941861, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 265 Loss: 0.5743919806591711\n",
      "In model, X: (500, 4), b: 0.2726550779511157, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 266 Loss: 0.5743662949839161\n",
      "In model, X: (500, 4), b: 0.27314324937751694, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 267 Loss: 0.5743407985190792\n",
      "In model, X: (500, 4), b: 0.2736294685792976, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 268 Loss: 0.5743154893351142\n",
      "In model, X: (500, 4), b: 0.2741137448959583, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 269 Loss: 0.574290365528565\n",
      "In model, X: (500, 4), b: 0.27459608760140236, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 270 Loss: 0.5742654252216228\n",
      "In model, X: (500, 4), b: 0.27507650590473043, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 271 Loss: 0.5742406665616901\n",
      "In model, X: (500, 4), b: 0.2755550089510206, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 272 Loss: 0.5742160877209562\n",
      "In model, X: (500, 4), b: 0.2760316058220937, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 273 Loss: 0.5741916868959789\n",
      "In model, X: (500, 4), b: 0.27650630553726524, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 274 Loss: 0.5741674623072773\n",
      "In model, X: (500, 4), b: 0.27697911705408285, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 275 Loss: 0.5741434121989305\n",
      "In model, X: (500, 4), b: 0.27745004926905087, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 276 Loss: 0.5741195348381859\n",
      "In model, X: (500, 4), b: 0.2779191110183417, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 277 Loss: 0.574095828515075\n",
      "In model, X: (500, 4), b: 0.2783863110784942, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 278 Loss: 0.5740722915420365\n",
      "In model, X: (500, 4), b: 0.27885165816709956, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 279 Loss: 0.5740489222535478\n",
      "In model, X: (500, 4), b: 0.27931516094347547, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 280 Loss: 0.5740257190057624\n",
      "In model, X: (500, 4), b: 0.27977682800932724, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 281 Loss: 0.5740026801761566\n",
      "In model, X: (500, 4), b: 0.28023666790939866, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 282 Loss: 0.5739798041631817\n",
      "In model, X: (500, 4), b: 0.28069468913211004, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 283 Loss: 0.5739570893859222\n",
      "In model, X: (500, 4), b: 0.2811509001101862, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 284 Loss: 0.5739345342837635\n",
      "In model, X: (500, 4), b: 0.2816053092212727, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 285 Loss: 0.5739121373160635\n",
      "In model, X: (500, 4), b: 0.2820579247885422, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 286 Loss: 0.5738898969618322\n",
      "In model, X: (500, 4), b: 0.2825087550812895, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 287 Loss: 0.5738678117194165\n",
      "In model, X: (500, 4), b: 0.2829578083155171, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 288 Loss: 0.5738458801061913\n",
      "In model, X: (500, 4), b: 0.28340509265451036, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 289 Loss: 0.5738241006582576\n",
      "In model, X: (500, 4), b: 0.28385061620940333, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 290 Loss: 0.5738024719301447\n",
      "In model, X: (500, 4), b: 0.2842943870397342, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 291 Loss: 0.5737809924945195\n",
      "In model, X: (500, 4), b: 0.28473641315399256, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 292 Loss: 0.573759660941901\n",
      "In model, X: (500, 4), b: 0.28517670251015637, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 293 Loss: 0.5737384758803794\n",
      "In model, X: (500, 4), b: 0.28561526301622087, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 294 Loss: 0.5737174359353419\n",
      "In model, X: (500, 4), b: 0.28605210253071833, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 295 Loss: 0.5736965397492026\n",
      "In model, X: (500, 4), b: 0.28648722886322925, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 296 Loss: 0.573675785981138\n",
      "In model, X: (500, 4), b: 0.28692064977488524, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 297 Loss: 0.5736551733068275\n",
      "In model, X: (500, 4), b: 0.28735237297886385, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 298 Loss: 0.5736347004181979\n",
      "In model, X: (500, 4), b: 0.287782406140875, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 299 Loss: 0.5736143660231746\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'w_hat' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[172], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      8\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m w, b, loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(loss)\n",
      "Cell \u001b[0;32mIn[168], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(w, b, X, y, iter, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m   losslist\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(myloss))\n\u001b[1;32m     16\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlosslist[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m w_hat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[43mw_hat\u001b[49m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m w_hat[\u001b[38;5;241m1\u001b[39m:], w_hat[\u001b[38;5;241m0\u001b[39m], losslist\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'w_hat' referenced before assignment"
     ]
    }
   ],
   "source": [
    "w = np.random.rand(X_train.shape[1],1)  # assuming X is N-by-n. \n",
    "                                        # if X is n-by-N, use X_train.shape[0]\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(w.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "b = 0\n",
    "w, b, loss = train(w, b, X_train, y_train, iter=300, lr=0.1)\n",
    "plt.figure()\n",
    "plt.plot(loss)\n",
    "\n",
    "#training accuracy \n",
    "z = model(w,b,X_train)\n",
    "print(accuracy(np.squeeze(y_train), predict(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41188, 35)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   1.,   1., ...,   1.,   1.,   1.],\n",
       "       [ 44., 210.,   1., ...,   0.,   1.,   0.],\n",
       "       [ 53., 138.,   1., ...,   0.,   1.,   0.],\n",
       "       ...,\n",
       "       [ 42.,  62.,   3., ...,   0.,   1.,   0.],\n",
       "       [ 48., 200.,   2., ...,   0.,   1.,   0.],\n",
       "       [ 25., 112.,   4., ...,   0.,   1.,   0.]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((np.ones((1,X.shape[1])),X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBm8ESACmrxe"
   },
   "source": [
    "To see how well our model performs, we compute its accuracy on the testing dataset (X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt9_Aiw-zqP6",
    "outputId": "7f79e3a5-af48-42d2-dc68-2e0294227c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In model, X: (500, 4), b: [-1.90193764], w: (4, 1)\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "z = model(w,b,X_test)\n",
    "y_test=np.squeeze(y_test)\n",
    "print(accuracy(y_test, predict(z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-YnkECyDJXw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef5x5LENm7_s"
   },
   "source": [
    "Now, we look at a real-world dataset. [The Bank Marketing Data Set](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#) is available at UCI's Machine Learning Repository. Colab can read this dataset directly from [GitHub](https://github.com/madmashup/targeted-marketing-predictive-engine) using pandas package: pd.read_csv. The data is in the DataFrame format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5vKPwXfYgLV",
    "outputId": "eed99c4f-7064-42d4-a417-8e135935854b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n",
      "['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/madmashup/targeted-marketing-predictive-engine/master/banking.csv'\n",
    "data = pd.read_csv(url)\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG9UWfJ8n2Jr"
   },
   "source": [
    "This dataset is pretty large and cause my machine to crash. I remove some fileds. [This Webpage](https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8) has a good description of this dataset. Note that you are not allowed to use any existing model such as those used in that Webpage for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "pGiNyyIsvUw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'housing', 'loan', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n",
      "(41188, 16)\n"
     ]
    }
   ],
   "source": [
    "cat_vars=['default','education','contact','month','day_of_week',]\n",
    "data=data.drop(cat_vars, axis=1)\n",
    "print(list(data.columns))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVSJRTDeoHNj"
   },
   "source": [
    "Some data columns have k class labels. This is best represented as k columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "du0e-Dhyg2FV",
    "outputId": "09fdef9c-d4ab-4be3-91c7-e04075f6f424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n",
      "marital\n",
      "housing\n",
      "loan\n",
      "poutcome\n",
      "(41188, 36)\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y', 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown', 'divorced', 'married', 'single', 'unknown', 'no', 'unknown', 'yes', 'no', 'unknown', 'yes', 'failure', 'nonexistent', 'success']\n"
     ]
    }
   ],
   "source": [
    "cat_vars=['job','marital','housing','loan','poutcome']\n",
    "for va in cat_vars:\n",
    "    #cat_pre='var'+'_'+var\n",
    "    print(va)\n",
    "    #print(data[va])\n",
    "    cat_list = pd.get_dummies(data[va])\n",
    "    data1=pd.concat([data,cat_list], axis=1)\n",
    "    data=data1.drop(va, axis=1)\n",
    "    #print(list(cat_list.columns))\n",
    "    #print(list(data.columns))\n",
    "    #print(data.shape)\n",
    "\n",
    "print(data.shape)\n",
    "print(list(data.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NazsRFZmpIuD"
   },
   "source": [
    "We now split the data into input data X and the label y. We covert them to numpy and split them into training and testing datasets with 30% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2kDuXGHtBdB",
    "outputId": "00966cf2-0715-4f2f-d500-5aebdfe9c4eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 35)\n",
      "(12357, 35)\n",
      "Index(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate',\n",
      "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'admin.',\n",
      "       'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired',\n",
      "       'self-employed', 'services', 'student', 'technician', 'unemployed',\n",
      "       'unknown', 'divorced', 'married', 'single', 'unknown', 'no', 'unknown',\n",
      "       'yes', 'no', 'unknown', 'yes', 'failure', 'nonexistent', 'success'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 'y']\n",
    "y = data.loc[:, data.columns == 'y']\n",
    "columns = X.columns\n",
    "X=X.to_numpy()\n",
    "y=y.to_numpy()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngDOmRz9pxyR"
   },
   "source": [
    "Now, train and test as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 1)\n",
      "(28831, 35)\n",
      "(28831, 1)\n",
      ">> (28831, 35)\n",
      "In model, X: (28831, 35), b: 0, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 0 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 1 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 2 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 3 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 4 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 5 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 6 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 7 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 8 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.01], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 9 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 10 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 11 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 12 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 13 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 14 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 15 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 16 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 17 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.02], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 18 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 19 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 20 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 21 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 22 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 23 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 24 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 25 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 26 Loss: 0.6931721775091231\n",
      "In model, X: (28831, 35), b: [-0.03], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 27 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 28 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 29 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 30 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 31 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 32 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 33 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 34 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 35 Loss: 0.6931826425503766\n",
      "In model, X: (28831, 35), b: [-0.04], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 36 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 37 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146295/1126415571.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 38 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 39 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 40 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 41 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 42 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 43 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 44 Loss: 0.6932312808265086\n",
      "In model, X: (28831, 35), b: [-0.05], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 45 Loss: 1.188192169565777\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 46 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 47 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 48 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 49 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 50 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 51 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 52 Loss: 0.6931936861112169\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 53 Loss: 0.6930305982305778\n",
      "In model, X: (28831, 35), b: [-0.06], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 54 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 55 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 56 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 57 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 58 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 59 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 60 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 61 Loss: 0.6932318593460958\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 62 Loss: 0.6931072889953762\n",
      "In model, X: (28831, 35), b: [-0.07], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 63 Loss: 1.197159331699143\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 64 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 65 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 66 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 67 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 68 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 69 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 70 Loss: 0.6931874865196846\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 71 Loss: 0.6928912445188098\n",
      "In model, X: (28831, 35), b: [-0.08], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 72 Loss: 1.0357792712417655\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 73 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 74 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 75 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 76 Loss: 0.6931721775091231\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 77 Loss: 0.6932444328815692\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 78 Loss: 0.6929305767697003\n",
      "In model, X: (28831, 35), b: [-0.09], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 79 Loss: 0.8908147421222169\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 80 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 81 Loss: 0.6932103507440021\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 82 Loss: 0.6932688755418006\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 83 Loss: 0.7018481570388908\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 84 Loss: 0.7044683487344056\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 85 Loss: 0.6983795859288561\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 86 Loss: 0.716089462393899\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 87 Loss: 0.6925644696787787\n",
      "In model, X: (28831, 35), b: [-0.1], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 88 Loss: 1.0420616109737035\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 89 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 90 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 91 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 92 Loss: 0.6931721775091231\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 93 Loss: 0.6932624773672187\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 94 Loss: 0.6925331961526645\n",
      "In model, X: (28831, 35), b: [-0.11], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 95 Loss: 0.9269289694086287\n",
      "In model, X: (28831, 35), b: [-0.12], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 96 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.12], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 97 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.12], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 98 Loss: 0.6931431136932739\n",
      "In model, X: (28831, 35), b: [-0.12], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 99 Loss: 0.6926296078812639\n",
      "In model, X: (28831, 35), b: [-0.12], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 100 Loss: 0.8561804647961497\n",
      "In model, X: (28831, 35), b: [-0.13], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 101 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.13], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 102 Loss: 0.6931597783260592\n",
      "In model, X: (28831, 35), b: [-0.13], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 103 Loss: 0.6927564159987556\n",
      "In model, X: (28831, 35), b: [-0.13], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 104 Loss: 0.8807110524668152\n",
      "In model, X: (28831, 35), b: [-0.14], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 105 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.14], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 106 Loss: 0.6932270153767874\n",
      "In model, X: (28831, 35), b: [-0.14], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 107 Loss: 0.6930348108097325\n",
      "In model, X: (28831, 35), b: [-0.14], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 108 Loss: 0.7257614596561617\n",
      "In model, X: (28831, 35), b: [-0.14], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 109 Loss: 0.6926249892912235\n",
      "In model, X: (28831, 35), b: [-0.14], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 110 Loss: 0.8799985766097326\n",
      "In model, X: (28831, 35), b: [-0.15], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 111 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.15], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 112 Loss: 0.6932006628053856\n",
      "In model, X: (28831, 35), b: [-0.15], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 113 Loss: 0.6929606666247558\n",
      "In model, X: (28831, 35), b: [-0.15], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 114 Loss: 0.7287777080003276\n",
      "In model, X: (28831, 35), b: [-0.15], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 115 Loss: 0.6926068535599815\n",
      "In model, X: (28831, 35), b: [-0.15], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 116 Loss: 0.8612449816793544\n",
      "In model, X: (28831, 35), b: [-0.16], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 117 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.16], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 118 Loss: 0.6931597783260592\n",
      "In model, X: (28831, 35), b: [-0.16], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 119 Loss: 0.6926595442630968\n",
      "In model, X: (28831, 35), b: [-0.16], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 120 Loss: 0.8314784110011224\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 121 Loss: 0.6932318593460958\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 122 Loss: 0.6933583982968813\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 123 Loss: 0.6990990321036538\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 124 Loss: 0.7127154222143075\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 125 Loss: 0.6922421405084884\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 126 Loss: 0.7754862467230631\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 127 Loss: 0.6932284689445003\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 128 Loss: 0.6919327065849944\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 129 Loss: 0.7813411077306768\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 130 Loss: 0.693222948510116\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 131 Loss: 0.6918273123726285\n",
      "In model, X: (28831, 35), b: [-0.17], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 132 Loss: 0.848256509282012\n",
      "In model, X: (28831, 35), b: [-0.18], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 133 Loss: 0.6931936861112169\n",
      "In model, X: (28831, 35), b: [-0.18], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 134 Loss: 0.6932277924794242\n",
      "In model, X: (28831, 35), b: [-0.18], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 135 Loss: 0.6920749825160116\n",
      "In model, X: (28831, 35), b: [-0.18], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 136 Loss: 0.852206723146933\n",
      "In model, X: (28831, 35), b: [-0.19], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 137 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.19], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 138 Loss: 0.6932111278466389\n",
      "In model, X: (28831, 35), b: [-0.19], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 139 Loss: 0.6922595427729267\n",
      "In model, X: (28831, 35), b: [-0.19], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 140 Loss: 0.8571317848569591\n",
      "In model, X: (28831, 35), b: [-0.2], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 141 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.2], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 142 Loss: 0.6931619990090294\n",
      "In model, X: (28831, 35), b: [-0.2], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 143 Loss: 0.692390107226502\n",
      "In model, X: (28831, 35), b: [-0.2], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 144 Loss: 0.8419349060152085\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 145 Loss: 0.6932367033154039\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 146 Loss: 0.6932022170106594\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 147 Loss: 0.691500260107596\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 148 Loss: 0.7616378383630306\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 149 Loss: 0.6932717853692981\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 150 Loss: 0.7041776150049468\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 151 Loss: 0.7011732515278322\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 152 Loss: 0.7070817347130912\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 153 Loss: 0.6984183000227169\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 154 Loss: 0.7159770510766786\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 155 Loss: 0.6912279450359373\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 156 Loss: 0.7998907423438685\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 157 Loss: 0.6931826425503766\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 158 Loss: 0.692321957370531\n",
      "In model, X: (28831, 35), b: [-0.21], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 159 Loss: 0.8195077826956382\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 160 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 161 Loss: 0.6930859626115099\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 162 Loss: 0.7160566623372236\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 163 Loss: 0.691278379029403\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 164 Loss: 0.7934975154401434\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 165 Loss: 0.6931646222953675\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 166 Loss: 0.6921735427539164\n",
      "In model, X: (28831, 35), b: [-0.22], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 167 Loss: 0.8712772566301791\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 168 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 169 Loss: 0.6932089951217784\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 170 Loss: 0.6926343137026483\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 171 Loss: 0.7763540191829014\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 172 Loss: 0.6931785756837051\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 173 Loss: 0.6920510113681098\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 174 Loss: 0.7568245599657528\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 175 Loss: 0.6931744497586217\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 176 Loss: 0.7121020077893433\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 177 Loss: 0.6940023028916176\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 178 Loss: 0.7441801050980292\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 179 Loss: 0.6926596075212268\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 180 Loss: 0.7683604704987997\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 181 Loss: 0.6931841967556502\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 182 Loss: 0.6975982893535596\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 183 Loss: 0.7238947460230455\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 184 Loss: 0.6918668668545049\n",
      "In model, X: (28831, 35), b: [-0.23], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 185 Loss: 0.898413133561861\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 186 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 187 Loss: 0.6932151947133104\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 188 Loss: 0.6931841967556502\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 189 Loss: 0.697414412563504\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 190 Loss: 0.7249155174184504\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 191 Loss: 0.6919231960271701\n",
      "In model, X: (28831, 35), b: [-0.24], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 192 Loss: 0.8937567558759272\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 193 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 194 Loss: 0.6932235270297029\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 195 Loss: 0.6931911738930675\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 196 Loss: 0.7002506829489135\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 197 Loss: 0.7108242498733776\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 198 Loss: 0.6956353872588769\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 199 Loss: 0.7360223546621011\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 200 Loss: 0.6921775929081366\n",
      "In model, X: (28831, 35), b: [-0.25], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 201 Loss: 0.8459616272033291\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 202 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 203 Loss: 0.6931632666731437\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 204 Loss: 0.690978900052127\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 205 Loss: 0.8095033914913247\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 206 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 207 Loss: 0.6927110245114673\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 208 Loss: 0.7597958980953188\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 209 Loss: 0.6931954388995405\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 210 Loss: 0.7064056319718461\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 211 Loss: 0.6989951178425786\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 212 Loss: 0.716929290246162\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 213 Loss: 0.6910409754482265\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 214 Loss: 0.7907658469116616\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 215 Loss: 0.6932041511524701\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 216 Loss: 0.691661373720763\n",
      "In model, X: (28831, 35), b: [-0.26], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 217 Loss: 0.9192099654929605\n",
      "In model, X: (28831, 35), b: [-0.27], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 218 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.27], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 219 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.27], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 220 Loss: 0.6931646222953675\n",
      "In model, X: (28831, 35), b: [-0.27], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 221 Loss: 0.6916258695351377\n",
      "In model, X: (28831, 35), b: [-0.27], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 222 Loss: 0.8724563577351333\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 223 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 224 Loss: 0.6932270153767874\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 225 Loss: 0.6924864493626544\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 226 Loss: 0.7692758991713807\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 227 Loss: 0.6931245511634929\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 228 Loss: 0.6972579773352967\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 229 Loss: 0.727738040755686\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 230 Loss: 0.6916858859904494\n",
      "In model, X: (28831, 35), b: [-0.28], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 231 Loss: 0.8738741361623912\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 232 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 233 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 234 Loss: 0.6925684781011041\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 235 Loss: 0.7611845506666911\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 236 Loss: 0.6931440893767997\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 237 Loss: 0.7040289884725024\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 238 Loss: 0.7013317559262134\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 239 Loss: 0.7073345293554735\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 240 Loss: 0.6982206551370396\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 241 Loss: 0.7232575392326178\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 242 Loss: 0.6907597857603803\n",
      "In model, X: (28831, 35), b: [-0.29], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 243 Loss: 0.8457592962966386\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 244 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 245 Loss: 0.69314175807105\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 246 Loss: 0.6911269803159588\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 247 Loss: 0.785928590905162\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 248 Loss: 0.693186130897461\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 249 Loss: 0.6907137103433479\n",
      "In model, X: (28831, 35), b: [-0.3], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 250 Loss: 0.8380472691003197\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 251 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 252 Loss: 0.6932014399080224\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 253 Loss: 0.6947971966242455\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 254 Loss: 0.748258988107139\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 255 Loss: 0.6928009659063654\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 256 Loss: 0.7472873166078704\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 257 Loss: 0.692718386768874\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 258 Loss: 0.7532812573897341\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 259 Loss: 0.6930740289479855\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 260 Loss: 0.7222741336006913\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 261 Loss: 0.6907698539621024\n",
      "In model, X: (28831, 35), b: [-0.31], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 262 Loss: 0.8256755097712201\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 263 Loss: 0.6931936861112169\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 264 Loss: 0.6931252920228268\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 265 Loss: 0.7025658025643366\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 266 Loss: 0.7043053482445587\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 267 Loss: 0.7007280556386453\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 268 Loss: 0.7095743528448569\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 269 Loss: 0.6961006933474699\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 270 Loss: 0.746577296119729\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 271 Loss: 0.6928646895613793\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 272 Loss: 0.7673392262805236\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 273 Loss: 0.6931667550202281\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 274 Loss: 0.6972545638741856\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 275 Loss: 0.7384943881253674\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 276 Loss: 0.6921967600141762\n",
      "In model, X: (28831, 35), b: [-0.32], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 277 Loss: 0.8709809256165432\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 278 Loss: 0.6931901977641324\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 279 Loss: 0.6932186830603948\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 280 Loss: 0.6925187858344419\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 281 Loss: 0.7949157946624996\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 282 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 283 Loss: 0.6914399111697895\n",
      "In model, X: (28831, 35), b: [-0.33], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 284 Loss: 0.9282003793341058\n",
      "In model, X: (28831, 35), b: [-0.34], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 285 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: [-0.34], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 286 Loss: 0.6931901977641324\n",
      "In model, X: (28831, 35), b: [-0.34], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 287 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: [-0.34], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 288 Loss: 0.6917653147501843\n",
      "In model, X: (28831, 35), b: [-0.34], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 289 Loss: 0.8585287108532496\n",
      "In model, X: (28831, 35), b: [-0.35], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 290 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.35], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 291 Loss: 0.6932221714074791\n",
      "In model, X: (28831, 35), b: [-0.35], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 292 Loss: 0.6910557452990075\n",
      "In model, X: (28831, 35), b: [-0.35], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 293 Loss: 0.8622451315489084\n",
      "In model, X: (28831, 35), b: [-0.36], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 294 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: [-0.36], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 295 Loss: 0.6932270153767874\n",
      "In model, X: (28831, 35), b: [-0.36], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 296 Loss: 0.6913887924898714\n",
      "In model, X: (28831, 35), b: [-0.36], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 297 Loss: 0.8388151305205459\n",
      "In model, X: (28831, 35), b: [-0.37], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 298 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: [-0.37], w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "Iter: 299 Loss: 0.6931535787345273\n",
      "In model, X: (28831, 35), b: [-0.37], w: (35, 1)\n",
      "0.9008705906836392\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w1 = np.random.rand(X_train1.shape[1],1)  # assuming X is N-by-n. \n",
    "                                        # if X is n-by-N, use X_train.shape[0]\n",
    "y_train1 = y_train1.reshape(-1,1)\n",
    "y_test1 = y_test1.reshape(-1,1)\n",
    "print(w1.shape)\n",
    "print(X_train1.shape)\n",
    "print(y_train1.shape)\n",
    "b1 = 0\n",
    "w1, b1, loss1 = train(w1, b1, X_train1, y_train1, iter=300, lr=0.01)\n",
    "plt.figure()\n",
    "plt.plot(loss1)\n",
    "\n",
    "#training accuracy \n",
    "z1 = model(w1,b1,X_train1)\n",
    "print(accuracy(np.squeeze(y_train1), predict(z1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In model, X: (12357, 35), b: [-0.37], w: (35, 1)\n",
      "0.9081492271586955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146295/1126415571.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n"
     ]
    }
   ],
   "source": [
    "z1 = model(w1,b1,X_test1)\n",
    "y_test1=np.squeeze(y_test1)\n",
    "print(accuracy(y_test1, predict(z1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
