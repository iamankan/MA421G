{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnzRlaQaW6y1"
   },
   "source": [
    "In this homework, you will write a python implementation of logistic regression. You will test it on two datasets. \n",
    "First we import some libraries that we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Szla9qyoPuqg"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0byO4vq0Xcxz"
   },
   "source": [
    "We define some functions involved. Use the formulations that avoid overflows.  \n",
    "1. sigmoid function sigmoid(t)\n",
    "2. log of sigmoid(t), called log_sig(t)\n",
    "3. log of 1-sigmoid = 1/(1+e^t), called log_one_sig(t)\n",
    "4. cross-entropy loss function given the inputs of label y and prediction y_hat = sigmoid(z), where y, y_hat, and z are vectors of dimension N. (N = # of data points.) You should implement this function with z, rather than y_hat, as the input; namely, the loss function should be\n",
    "\n",
    "    loss = -y log(sigmoid(z)) - (1-y) log (1-sigmoid(z)) \n",
    "\n",
    "  where log(sigmoid(z)) and log (1-sigmoid(z)) should be computed by the functions log_sig(z) and log_one_sig(z) in parts 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kuzmD54GT9yb"
   },
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "      return 1/(1+np.exp(-t))\n",
    "\n",
    "def custom_loss(y, z):\n",
    "    return ((-y*log_sig(z)) - ((1-y)*log_one_sig(z)))\n",
    "\n",
    "def log_sig(t):\n",
    "      return np.log(sigmoid(t))\n",
    "\n",
    "def log_one_sig(t):\n",
    "      return np.log(1-sigmoid(t))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLulJqXcbEpw"
   },
   "source": [
    "Define the model output z=w^T x + b, or z = x^Tw + B, given the data input X (an N-by-n array containing N data points) and the model parameters w (n-dimensional weigth vector) and b (bias).\n",
    "\n",
    "Note that mathematically it's easier to write the data matrix as an n-by-N matrix, with each column being a data point. In python, the data is more commonly represented as as an N-by-n array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "eI9PNMZnhy0d"
   },
   "outputs": [],
   "source": [
    "def model(w,b,X):\n",
    "  # using X as Nxn\n",
    "  print(f'In model, X: {X.shape}, b: {b}, w: {w.shape}')\n",
    "  return (X @ w)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vv_xi0ajaEEY"
   },
   "source": [
    "Define the function that computes the gradient of the cross-entropy loss given the label y (N-vector), the model prediction y_hat = sigmoid(z) (N-vector), and the dataset X (an n-by-N or N-by-n array). It's probably easier to return the gradients with respect w and b separately, which can be used to update w and b later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "I8KJF8lrZlFi"
   },
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "  # Using X as Nxn\n",
    "  print(f'grad: y shape: {y.shape}, X shape: {X.shape}')\n",
    "  return (np.transpose(X) @ (y_hat - y))/X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wgqML9T2cOqd"
   },
   "source": [
    "Write the function that minimizes the loss (i.e. training) by the gradient descent algorithm using a fixed number of iteration (*iter*) and learning rate (*lr*). Your function should take *iter* and *lr* as well as the initial weight w, initial bias b, the input data X and the label y as the inputs. It produces new w and b as output. Also compute the loss value at each iteration and output the sequence of the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "6bIdE16li086"
   },
   "outputs": [],
   "source": [
    "def train(w, b, X, y, iter, lr):\n",
    "  print(f'>> {X.shape}')\n",
    "  losslist=list()\n",
    "  print('>>',X.shape)\n",
    "  for k in range(iter):\n",
    "    z = model(w, b, X)\n",
    "    y_hat = sigmoid(z)\n",
    "    grad = gradients(X, y, y_hat)\n",
    "    print(f'gradient shape: {grad.shape}')\n",
    "    w = w - (lr * grad)\n",
    "    print(f'y_hat: {y_hat.shape}, y: {y.shape}')\n",
    "#     b = b - (lr * (y_hat - y)[0])\n",
    "    b = np.mean((b*np.ones(y_hat.shape)) - (lr * (y_hat - y)))\n",
    "    myloss = custom_loss(y, y_hat)\n",
    "    losslist.append(np.mean(myloss))\n",
    "    print(f'Iter: {k} Loss: {losslist[-1]}')\n",
    "  return w, b, losslist\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGC-EjrzeHyU"
   },
   "source": [
    "1. Write the function that uses a trained model to produce class prediction (0 or 1) for an input dataset X, i.e. turn the model output z = model(w,b,X) into predicted label y_label (N-vector of 0 or 1). \n",
    "2. For an input dataset X with a known label y (e.g. a training or testing dataset) and a predicted label y_label, compute the accuracy of prediction (i.e. # correct predictions/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "HChwCsuWf07D"
   },
   "outputs": [],
   "source": [
    "def predict(z):\n",
    "  ypred = sigmoid(z)\n",
    "  ypred[ypred<=0.5]=0\n",
    "  ypred[ypred>0.5]=1\n",
    "  ypred = ypred.astype(int)\n",
    "  ypred = np.squeeze(ypred)\n",
    "  # print(f'In pred, {ypred.shape}')\n",
    "  return ypred\n",
    "\n",
    "def accuracy(y, y_label):\n",
    "  diff_bool = (y == y_label)\n",
    "  diff_true = diff_bool[diff_bool==True]\n",
    "  total_sample = len(diff_bool)\n",
    "  return (len(diff_true)/total_sample)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "icfCmavagcp5"
   },
   "source": [
    "We are ready to test your programs on some datasets. First, we use a synthetic dataset generated using [scikit-learn](https://scikit-learn.org/stable/datasets.html) package. We generate a dataset for training and simultaneously a dataset for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "EXJOlxH2nYw3",
    "outputId": "a2ffea0e-e5d7-4904-81d3-3c65d9dac67d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc510699b70>]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "X_train, y_train = make_moons(n_samples=500, noise=0.1)\n",
    "X_test, y_test = make_moons(n_samples=1000, noise=0.1)\n",
    "\n",
    "print(X_train.shape)\n",
    "plt.figure()\n",
    "plt.plot(X_train[:, 0][y_train==0], X_train[:, 1][y_train==0], \"g^\")\n",
    "plt.plot(X_train[:, 0][y_train==1], X_train[:, 1][y_train==1], \"bs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2_uUM_Zufoz"
   },
   "source": [
    "Here is another toy test example you may try but not part of homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "EJbVzPfLdOvC",
    "outputId": "91844d24-7e83-418c-91af-70f6c41b1272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc510476920>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "X_train, y_train = make_classification(n_samples=1000, n_features=4)\n",
    "X_test=X_train[500:,]\n",
    "y_test=y_train[500:,]\n",
    "X_train=X_train[:500,]\n",
    "y_train=y_train[:500,]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(X_train[:, 0][y_train==0], X_train[:, 1][y_train==0], \"g^\")\n",
    "plt.plot(X_train[:, 0][y_train==1], X_train[:, 1][y_train==1], \"bs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMm__k_AjOFp"
   },
   "source": [
    "We now train the model using (X_train, y_train). We initialize weight as a random vector, and b=0. We plot the loss convergence history. You should get the loss down to about 0.2.\n",
    "We compute the prediction accuracy on (X_train, y_train). You should get an accuracy in the 80s. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "mi868jT_mpnq",
    "outputId": "f6d75f4c-6a30-41c5-fceb-eb621f7fd69c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1)\n",
      "(500, 4)\n",
      "(500, 1)\n",
      ">> (500, 4)\n",
      ">> (500, 4)\n",
      "In model, X: (500, 4), b: 0, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 0 Loss: 0.6226764966297005\n",
      "In model, X: (500, 4), b: -0.0013673338087844612, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 1 Loss: 0.6210669442051474\n",
      "In model, X: (500, 4), b: -0.0026784120427167405, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 2 Loss: 0.6195480871088982\n",
      "In model, X: (500, 4), b: -0.003935041941194865, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 3 Loss: 0.6181124974334864\n",
      "In model, X: (500, 4), b: -0.0051390404866494595, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 4 Loss: 0.6167534752718599\n",
      "In model, X: (500, 4), b: -0.006292218845016928, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 5 Loss: 0.6154649747993417\n",
      "In model, X: (500, 4), b: -0.007396370023888878, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 6 Loss: 0.6142415364630631\n",
      "In model, X: (500, 4), b: -0.008453259206560934, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 7 Loss: 0.613078225390198\n",
      "In model, X: (500, 4), b: -0.009464616299782907, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 8 Loss: 0.611970575850828\n",
      "In model, X: (500, 4), b: -0.010432130304074153, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 9 Loss: 0.6109145414465795\n",
      "In model, X: (500, 4), b: -0.011357445177680439, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 10 Loss: 0.6099064506070735\n",
      "In model, X: (500, 4), b: -0.012242156918947486, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 11 Loss: 0.6089429669375519\n",
      "In model, X: (500, 4), b: -0.013087811637755986, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 12 Loss: 0.6080210539550039\n",
      "In model, X: (500, 4), b: -0.013895904425538546, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 13 Loss: 0.6071379437644271\n",
      "In model, X: (500, 4), b: -0.01466787886614992, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 14 Loss: 0.6062911092530785\n",
      "In model, X: (500, 4), b: -0.01540512705732478, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 15 Loss: 0.6054782394130278\n",
      "In model, X: (500, 4), b: -0.016108990035402122, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 16 Loss: 0.6046972174373201\n",
      "In model, X: (500, 4), b: -0.01678075851510981, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 17 Loss: 0.6039461012701763\n",
      "In model, X: (500, 4), b: -0.0174216738720891, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 18 Loss: 0.6032231063254755\n",
      "In model, X: (500, 4), b: -0.018032929309017256, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 19 Loss: 0.6025265901194184\n",
      "In model, X: (500, 4), b: -0.0186156711571004, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 20 Loss: 0.6018550385923561\n",
      "In model, X: (500, 4), b: -0.019171000273735365, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 21 Loss: 0.6012070539211256\n",
      "In model, X: (500, 4), b: -0.019699973504595392, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 22 Loss: 0.6005813436468875\n",
      "In model, X: (500, 4), b: -0.020203605184545937, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 23 Loss: 0.5999767109645261\n",
      "In model, X: (500, 4), b: -0.020682868656866332, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 24 Loss: 0.5993920460383402\n",
      "In model, X: (500, 4), b: -0.02113869779442548, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 25 Loss: 0.5988263182252124\n",
      "In model, X: (500, 4), b: -0.021571988509889325, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 26 Loss: 0.5982785691009345\n",
      "In model, X: (500, 4), b: -0.021983600244852994, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 27 Loss: 0.5977479061980634\n",
      "In model, X: (500, 4), b: -0.02237435743009683, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 28 Loss: 0.5972334973748339\n",
      "In model, X: (500, 4), b: -0.022745050911051674, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 29 Loss: 0.5967345657443843\n",
      "In model, X: (500, 4), b: -0.023096439334097267, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 30 Loss: 0.5962503851020949\n",
      "In model, X: (500, 4), b: -0.023429250490569306, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 31 Loss: 0.5957802757962763\n",
      "In model, X: (500, 4), b: -0.023744182616365118, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 32 Loss: 0.5953236009939832\n",
      "In model, X: (500, 4), b: -0.024041905645857023, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 33 Loss: 0.5948797632994158\n",
      "In model, X: (500, 4), b: -0.02432306241948016, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 34 Loss: 0.5944482016873728\n",
      "In model, X: (500, 4), b: -0.024588269844886382, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 35 Loss: 0.5940283887185779\n",
      "In model, X: (500, 4), b: -0.024838120011971398, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 36 Loss: 0.5936198280075384\n",
      "In model, X: (500, 4), b: -0.02507318126240793, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 37 Loss: 0.5932220519169404\n",
      "In model, X: (500, 4), b: -0.025293999214569474, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 38 Loss: 0.5928346194555356\n",
      "In model, X: (500, 4), b: -0.025501097744920653, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 39 Loss: 0.5924571143590565\n",
      "In model, X: (500, 4), b: -0.02569497992709215, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 40 Loss: 0.5920891433359725\n",
      "In model, X: (500, 4), b: -0.025876128929959892, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 41 Loss: 0.5917303344618986\n",
      "In model, X: (500, 4), b: -0.02604500887611731, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 42 Loss: 0.5913803357082306\n",
      "In model, X: (500, 4), b: -0.026202065662171845, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 43 Loss: 0.5910388135921385\n",
      "In model, X: (500, 4), b: -0.02634772774231844, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 44 Loss: 0.5907054519364177\n",
      "In model, X: (500, 4), b: -0.026482406876646828, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 45 Loss: 0.5903799507289152\n",
      "In model, X: (500, 4), b: -0.026606498845630273, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 46 Loss: 0.5900620250723223\n",
      "In model, X: (500, 4), b: -0.0267203841322237, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 47 Loss: 0.589751404216072\n",
      "In model, X: (500, 4), b: -0.026824428572970946, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 48 Loss: 0.5894478306629288\n",
      "In model, X: (500, 4), b: -0.026918983979486784, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 49 Loss: 0.5891510593436101\n",
      "In model, X: (500, 4), b: -0.027004388731640294, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 50 Loss: 0.5888608568534355\n",
      "In model, X: (500, 4), b: -0.02708096834372406, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 51 Loss: 0.5885770007456058\n",
      "In model, X: (500, 4), b: -0.027149036004848966, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 52 Loss: 0.5882992788762357\n",
      "In model, X: (500, 4), b: -0.027208893094758643, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 53 Loss: 0.5880274887967377\n",
      "In model, X: (500, 4), b: -0.02726082967621079, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 54 Loss: 0.5877614371895771\n",
      "In model, X: (500, 4), b: -0.02730512496502593, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 55 Loss: 0.5875009393437965\n",
      "In model, X: (500, 4), b: -0.02734204777885771, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 56 Loss: 0.5872458186670427\n",
      "In model, X: (500, 4), b: -0.027371856965692772, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 57 Loss: 0.586995906231137\n",
      "In model, X: (500, 4), b: -0.027394801813043646, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 58 Loss: 0.5867510403484942\n",
      "In model, X: (500, 4), b: -0.02741112243875392, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 59 Loss: 0.5865110661769525\n",
      "In model, X: (500, 4), b: -0.0274210501642927, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 60 Loss: 0.5862758353507769\n",
      "In model, X: (500, 4), b: -0.027424807871374066, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 61 Loss: 0.5860452056358195\n",
      "In model, X: (500, 4), b: -0.027422610342697464, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 62 Loss: 0.5858190406069793\n",
      "In model, X: (500, 4), b: -0.027414664587566983, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 63 Loss: 0.5855972093462756\n",
      "In model, X: (500, 4), b: -0.02740117015311056, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 64 Loss: 0.58537958615999\n",
      "In model, X: (500, 4), b: -0.02738231942178517, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 65 Loss: 0.5851660503134695\n",
      "In model, X: (500, 4), b: -0.027358297895820356, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 66 Loss: 0.5849564857822898\n",
      "In model, X: (500, 4), b: -0.02732928446922037, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 67 Loss: 0.5847507810186029\n",
      "In model, X: (500, 4), b: -0.027295451687914585, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 68 Loss: 0.5845488287315749\n",
      "In model, X: (500, 4), b: -0.027256965998616507, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 69 Loss: 0.5843505256809193\n",
      "In model, X: (500, 4), b: -0.027213987986924017, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 70 Loss: 0.5841557724826069\n",
      "In model, X: (500, 4), b: -0.027166672605166906, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 71 Loss: 0.5839644734259091\n",
      "In model, X: (500, 4), b: -0.02711516939048267, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 72 Loss: 0.5837765363009965\n",
      "In model, X: (500, 4), b: -0.02705962267357747, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 73 Loss: 0.5835918722363759\n",
      "In model, X: (500, 4), b: -0.027000171778606585, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 74 Loss: 0.5834103955455081\n",
      "In model, X: (500, 4), b: -0.026936951214586898, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 75 Loss: 0.5832320235819932\n",
      "In model, X: (500, 4), b: -0.02687009085873362, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 76 Loss: 0.583056676602761\n",
      "In model, X: (500, 4), b: -0.026799716132093934, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 77 Loss: 0.5828842776387464\n",
      "In model, X: (500, 4), b: -0.02672594816783171, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 78 Loss: 0.5827147523725676\n",
      "In model, X: (500, 4), b: -0.026648903972500037, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 79 Loss: 0.5825480290227593\n",
      "In model, X: (500, 4), b: -0.02656869658062162, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 80 Loss: 0.5823840382341472\n",
      "In model, X: (500, 4), b: -0.026485435202881377, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 81 Loss: 0.5822227129739828\n",
      "In model, X: (500, 4), b: -0.026399225368220605, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 82 Loss: 0.5820639884334777\n",
      "In model, X: (500, 4), b: -0.026310169060107844, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 83 Loss: 0.5819078019344099\n",
      "In model, X: (500, 4), b: -0.026218364847248283, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 84 Loss: 0.581754092840493\n",
      "In model, X: (500, 4), b: -0.026123908008980613, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 85 Loss: 0.581602802473222\n",
      "In model, X: (500, 4), b: -0.02602689065559831, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 86 Loss: 0.5814538740319297\n",
      "In model, X: (500, 4), b: -0.02592740184382071, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 87 Loss: 0.5813072525178051\n",
      "In model, X: (500, 4), b: -0.025825527687628493, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 88 Loss: 0.5811628846616436\n",
      "In model, X: (500, 4), b: -0.025721351464667783, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 89 Loss: 0.5810207188551094\n",
      "In model, X: (500, 4), b: -0.025614953718417346, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 90 Loss: 0.580880705085315\n",
      "In model, X: (500, 4), b: -0.02550641235630403, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 91 Loss: 0.5807427948725228\n",
      "In model, X: (500, 4), b: -0.02539580274394281, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 92 Loss: 0.5806069412107981\n",
      "In model, X: (500, 4), b: -0.02528319779566945, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 93 Loss: 0.5804730985114455\n",
      "In model, X: (500, 4), b: -0.02516866806152585, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 94 Loss: 0.5803412225490767\n",
      "In model, X: (500, 4), b: -0.02505228181085054, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 95 Loss: 0.5802112704101662\n",
      "In model, X: (500, 4), b: -0.02493410511261981, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 96 Loss: 0.5800832004439566\n",
      "In model, X: (500, 4), b: -0.024814201912677986, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 97 Loss: 0.5799569722155902\n",
      "In model, X: (500, 4), b: -0.02469263410798898, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 98 Loss: 0.5798325464613471\n",
      "In model, X: (500, 4), b: -0.02456946161803522, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 99 Loss: 0.5797098850458775\n",
      "In model, X: (500, 4), b: -0.024444742453484082, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 100 Loss: 0.5795889509213246\n",
      "In model, X: (500, 4), b: -0.024318532782236515, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 101 Loss: 0.5794697080882395\n",
      "In model, X: (500, 4), b: -0.02419088699296731, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 102 Loss: 0.5793521215581953\n",
      "In model, X: (500, 4), b: -0.024061857756261382, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 103 Loss: 0.5792361573180131\n",
      "In model, X: (500, 4), b: -0.0239314960834458, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 104 Loss: 0.5791217822955202\n",
      "In model, X: (500, 4), b: -0.023799851383212726, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 105 Loss: 0.5790089643267604\n",
      "In model, X: (500, 4), b: -0.023666971516124125, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 106 Loss: 0.5788976721245859\n",
      "In model, X: (500, 4), b: -0.023532902847085046, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 107 Loss: 0.578787875248561\n",
      "In model, X: (500, 4), b: -0.02339769029586841, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 108 Loss: 0.5786795440761162\n",
      "In model, X: (500, 4), b: -0.02326137738577048, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 109 Loss: 0.5785726497748868\n",
      "In model, X: (500, 4), b: -0.023124006290472784, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 110 Loss: 0.5784671642761822\n",
      "In model, X: (500, 4), b: -0.022985617879182792, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 111 Loss: 0.5783630602495325\n",
      "In model, X: (500, 4), b: -0.022846251760122553, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 112 Loss: 0.5782603110782566\n",
      "In model, X: (500, 4), b: -0.022705946322431395, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 113 Loss: 0.5781588908360079\n",
      "In model, X: (500, 4), b: -0.022564738776545985, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 114 Loss: 0.5780587742642501\n",
      "In model, X: (500, 4), b: -0.022422665193118207, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 115 Loss: 0.5779599367506192\n",
      "In model, X: (500, 4), b: -0.02227976054052875, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 116 Loss: 0.5778623543081315\n",
      "In model, X: (500, 4), b: -0.02213605872105176, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 117 Loss: 0.5777660035551989\n",
      "In model, X: (500, 4), b: -0.021991592605723607, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 118 Loss: 0.577670861696414\n",
      "In model, X: (500, 4), b: -0.021846394067966388, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 119 Loss: 0.5775769065040701\n",
      "In model, X: (500, 4), b: -0.021700494016014822, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 120 Loss: 0.5774841163003855\n",
      "In model, X: (500, 4), b: -0.02155392242419301, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 121 Loss: 0.5773924699403958\n",
      "In model, X: (500, 4), b: -0.021406708363085527, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 122 Loss: 0.5773019467954906\n",
      "In model, X: (500, 4), b: -0.021258880028645552, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 123 Loss: 0.5772125267375608\n",
      "In model, X: (500, 4), b: -0.02111046477028087, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 124 Loss: 0.5771241901237341\n",
      "In model, X: (500, 4), b: -0.020961489117956887, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 125 Loss: 0.5770369177816697\n",
      "In model, X: (500, 4), b: -0.020811978808354163, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 126 Loss: 0.5769506909953922\n",
      "In model, X: (500, 4), b: -0.02066195881011642, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 127 Loss: 0.576865491491636\n",
      "In model, X: (500, 4), b: -0.020511453348223498, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 128 Loss: 0.5767813014266845\n",
      "In model, X: (500, 4), b: -0.020360485927522265, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 129 Loss: 0.5766981033736792\n",
      "In model, X: (500, 4), b: -0.020209079355447208, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 130 Loss: 0.5766158803103801\n",
      "In model, X: (500, 4), b: -0.02005725576396106, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 131 Loss: 0.5765346156073592\n",
      "In model, X: (500, 4), b: -0.01990503663074459, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 132 Loss: 0.5764542930166083\n",
      "In model, X: (500, 4), b: -0.019752442799663594, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 133 Loss: 0.5763748966605454\n",
      "In model, X: (500, 4), b: -0.019599494500539823, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 134 Loss: 0.5762964110214007\n",
      "In model, X: (500, 4), b: -0.019446211368251646, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 135 Loss: 0.57621882093097\n",
      "In model, X: (500, 4), b: -0.019292612461189136, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 136 Loss: 0.5761421115607192\n",
      "In model, X: (500, 4), b: -0.019138716279087333, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 137 Loss: 0.5760662684122246\n",
      "In model, X: (500, 4), b: -0.018984540780260396, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 138 Loss: 0.5759912773079386\n",
      "In model, X: (500, 4), b: -0.018830103398258576, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 139 Loss: 0.5759171243822645\n",
      "In model, X: (500, 4), b: -0.01867542105796896, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 140 Loss: 0.575843796072931\n",
      "In model, X: (500, 4), b: -0.018520510191180194, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 141 Loss: 0.5757712791126531\n",
      "In model, X: (500, 4), b: -0.018365386751630502, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 142 Loss: 0.5756995605210691\n",
      "In model, X: (500, 4), b: -0.018210066229557717, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 143 Loss: 0.5756286275969418\n",
      "In model, X: (500, 4), b: -0.018054563665769102, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 144 Loss: 0.5755584679106159\n",
      "In model, X: (500, 4), b: -0.017898893665248213, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 145 Loss: 0.5754890692967198\n",
      "In model, X: (500, 4), b: -0.01774307041031531, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 146 Loss: 0.5754204198471022\n",
      "In model, X: (500, 4), b: -0.017587107673357222, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 147 Loss: 0.5753525079039981\n",
      "In model, X: (500, 4), b: -0.017431018829141883, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 148 Loss: 0.5752853220534104\n",
      "In model, X: (500, 4), b: -0.01727481686673231, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 149 Loss: 0.5752188511187045\n",
      "In model, X: (500, 4), b: -0.017118514401014005, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 150 Loss: 0.5751530841544027\n",
      "In model, X: (500, 4), b: -0.01696212368384955, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 151 Loss: 0.5750880104401753\n",
      "In model, X: (500, 4), b: -0.016805656614873266, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 152 Loss: 0.5750236194750191\n",
      "In model, X: (500, 4), b: -0.016649124751938655, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 153 Loss: 0.5749599009716166\n",
      "In model, X: (500, 4), b: -0.016492539321230636, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 154 Loss: 0.5748968448508698\n",
      "In model, X: (500, 4), b: -0.01633591122705423, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 155 Loss: 0.5748344412366017\n",
      "In model, X: (500, 4), b: -0.016179251061310906, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 156 Loss: 0.5747726804504207\n",
      "In model, X: (500, 4), b: -0.016022569112673368, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 157 Loss: 0.57471155300674\n",
      "In model, X: (500, 4), b: -0.01586587537546914, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 158 Loss: 0.5746510496079495\n",
      "In model, X: (500, 4), b: -0.01570917955828296, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 159 Loss: 0.5745911611397307\n",
      "In model, X: (500, 4), b: -0.015552491092287617, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 160 Loss: 0.5745318786665141\n",
      "In model, X: (500, 4), b: -0.015395819139312443, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 161 Loss: 0.5744731934270708\n",
      "In model, X: (500, 4), b: -0.015239172599658447, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 162 Loss: 0.574415096830235\n",
      "In model, X: (500, 4), b: -0.015082560119668648, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 163 Loss: 0.5743575804507522\n",
      "In model, X: (500, 4), b: -0.014925990099061905, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 164 Loss: 0.5743006360252509\n",
      "In model, X: (500, 4), b: -0.014769470698038188, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 165 Loss: 0.574244255448329\n",
      "In model, X: (500, 4), b: -0.014613009844163043, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 166 Loss: 0.5741884307687567\n",
      "In model, X: (500, 4), b: -0.014456615239038583, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 167 Loss: 0.5741331541857876\n",
      "In model, X: (500, 4), b: -0.014300294364768217, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 168 Loss: 0.5740784180455765\n",
      "In model, X: (500, 4), b: -0.014144054490221918, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 169 Loss: 0.5740242148376985\n",
      "In model, X: (500, 4), b: -0.013987902677108753, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 170 Loss: 0.5739705371917696\n",
      "In model, X: (500, 4), b: -0.013831845785863009, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 171 Loss: 0.5739173778741601\n",
      "In model, X: (500, 4), b: -0.0136758904813501, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 172 Loss: 0.5738647297848035\n",
      "In model, X: (500, 4), b: -0.01352004323839821, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 173 Loss: 0.5738125859540928\n",
      "In model, X: (500, 4), b: -0.0133643103471614, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 174 Loss: 0.5737609395398645\n",
      "In model, X: (500, 4), b: -0.013208697918319714, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 175 Loss: 0.573709783824466\n",
      "In model, X: (500, 4), b: -0.013053211888121618, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 176 Loss: 0.5736591122119048\n",
      "In model, X: (500, 4), b: -0.012897858023273928, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 177 Loss: 0.5736089182250756\n",
      "In model, X: (500, 4), b: -0.012742641925684181, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 178 Loss: 0.5735591955030628\n",
      "In model, X: (500, 4), b: -0.01258756903706026, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 179 Loss: 0.5735099377985182\n",
      "In model, X: (500, 4), b: -0.01243264464337188, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 180 Loss: 0.5734611389751083\n",
      "In model, X: (500, 4), b: -0.012277873879178423, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 181 Loss: 0.5734127930050313\n",
      "In model, X: (500, 4), b: -0.012123261731827394, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 182 Loss: 0.5733648939666007\n",
      "In model, X: (500, 4), b: -0.0119688130455277, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 183 Loss: 0.5733174360418939\n",
      "In model, X: (500, 4), b: -0.011814532525301744, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 184 Loss: 0.5732704135144633\n",
      "In model, X: (500, 4), b: -0.011660424740820208, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 185 Loss: 0.5732238207671071\n",
      "In model, X: (500, 4), b: -0.01150649413012328, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 186 Loss: 0.5731776522797009\n",
      "In model, X: (500, 4), b: -0.011352745003231935, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 187 Loss: 0.5731319026270849\n",
      "In model, X: (500, 4), b: -0.011199181545652775, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 188 Loss: 0.5730865664770065\n",
      "In model, X: (500, 4), b: -0.011045807821779772, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 189 Loss: 0.5730416385881173\n",
      "In model, X: (500, 4), b: -0.010892627778196193, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 190 Loss: 0.5729971138080209\n",
      "In model, X: (500, 4), b: -0.010739645246879858, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 191 Loss: 0.572952987071372\n",
      "In model, X: (500, 4), b: -0.010586863948314758, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 192 Loss: 0.5729092533980243\n",
      "In model, X: (500, 4), b: -0.01043428749451198, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 193 Loss: 0.5728659078912252\n",
      "In model, X: (500, 4), b: -0.010281919391942769, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 194 Loss: 0.5728229457358567\n",
      "In model, X: (500, 4), b: -0.010129763044386474, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 195 Loss: 0.5727803621967221\n",
      "In model, X: (500, 4), b: -0.009977821755696045, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 196 Loss: 0.5727381526168737\n",
      "In model, X: (500, 4), b: -0.009826098732483626, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 197 Loss: 0.5726963124159846\n",
      "In model, X: (500, 4), b: -0.009674597086728721, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 198 Loss: 0.5726548370887609\n",
      "In model, X: (500, 4), b: -0.009523319838311341, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 199 Loss: 0.5726137222033915\n",
      "In model, X: (500, 4), b: -0.009372269917472436, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 200 Loss: 0.5725729634000407\n",
      "In model, X: (500, 4), b: -0.009221450167203863, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 201 Loss: 0.5725325563893725\n",
      "In model, X: (500, 4), b: -0.009070863345570042, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 202 Loss: 0.5724924969511163\n",
      "In model, X: (500, 4), b: -0.00892051212796341, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 203 Loss: 0.5724527809326642\n",
      "In model, X: (500, 4), b: -0.008770399109295678, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 204 Loss: 0.5724134042477048\n",
      "In model, X: (500, 4), b: -0.008620526806126872, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 205 Loss: 0.5723743628748893\n",
      "In model, X: (500, 4), b: -0.00847089765873404, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 206 Loss: 0.5723356528565292\n",
      "In model, X: (500, 4), b: -0.008321514033121442, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 207 Loss: 0.5722972702973276\n",
      "In model, X: (500, 4), b: -0.008172378222974053, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 208 Loss: 0.5722592113631378\n",
      "In model, X: (500, 4), b: -0.00802349245155602, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 209 Loss: 0.5722214722797547\n",
      "In model, X: (500, 4), b: -0.007874858873555785, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 210 Loss: 0.572184049331733\n",
      "In model, X: (500, 4), b: -0.007726479576879472, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 211 Loss: 0.5721469388612341\n",
      "In model, X: (500, 4), b: -0.007578356584394078, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 212 Loss: 0.5721101372669006\n",
      "In model, X: (500, 4), b: -0.007430491855621985, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 213 Loss: 0.572073641002756\n",
      "In model, X: (500, 4), b: -0.0072828872883882465, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 214 Loss: 0.5720374465771322\n",
      "In model, X: (500, 4), b: -0.00713554472042206, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 215 Loss: 0.57200155055162\n",
      "In model, X: (500, 4), b: -0.006988465930913796, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 216 Loss: 0.5719659495400455\n",
      "In model, X: (500, 4), b: -0.006841652642028881, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 217 Loss: 0.5719306402074693\n",
      "In model, X: (500, 4), b: -0.006695106520379856, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 218 Loss: 0.571895619269209\n",
      "In model, X: (500, 4), b: -0.006548829178457813, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 219 Loss: 0.5718608834898842\n",
      "In model, X: (500, 4), b: -0.006402822176024417, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 220 Loss: 0.5718264296824844\n",
      "In model, X: (500, 4), b: -0.006257087021465695, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 221 Loss: 0.5717922547074559\n",
      "In model, X: (500, 4), b: -0.006111625173108696, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 222 Loss: 0.5717583554718112\n",
      "In model, X: (500, 4), b: -0.005966438040502117, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 223 Loss: 0.5717247289282581\n",
      "In model, X: (500, 4), b: -0.005821526985661965, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 224 Loss: 0.5716913720743483\n",
      "In model, X: (500, 4), b: -0.005676893324283247, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 225 Loss: 0.5716582819516451\n",
      "In model, X: (500, 4), b: -0.005532538326918722, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 226 Loss: 0.5716254556449103\n",
      "In model, X: (500, 4), b: -0.005388463220125639, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 227 Loss: 0.5715928902813076\n",
      "In model, X: (500, 4), b: -0.005244669187581398, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 228 Loss: 0.5715605830296258\n",
      "In model, X: (500, 4), b: -0.005101157371169057, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 229 Loss: 0.5715285310995177\n",
      "In model, X: (500, 4), b: -0.004957928872033536, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 230 Loss: 0.5714967317407567\n",
      "In model, X: (500, 4), b: -0.0048149847516093655, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 231 Loss: 0.5714651822425081\n",
      "In model, X: (500, 4), b: -0.004672326032620816, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 232 Loss: 0.5714338799326185\n",
      "In model, X: (500, 4), b: -0.00452995370005519, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 233 Loss: 0.5714028221769197\n",
      "In model, X: (500, 4), b: -0.004387868702110052, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 234 Loss: 0.5713720063785461\n",
      "In model, X: (500, 4), b: -0.004246071951115142, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 235 Loss: 0.5713414299772706\n",
      "In model, X: (500, 4), b: -0.004104564324429698, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 236 Loss: 0.5713110904488506\n",
      "In model, X: (500, 4), b: -0.003963346665315893, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 237 Loss: 0.5712809853043914\n",
      "In model, X: (500, 4), b: -0.0038224197837890637, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 238 Loss: 0.5712511120897209\n",
      "In model, X: (500, 4), b: -0.003681784457445391, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 239 Loss: 0.5712214683847787\n",
      "In model, X: (500, 4), b: -0.00354144143226767, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 240 Loss: 0.5711920518030188\n",
      "In model, X: (500, 4), b: -0.003401391423409804, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 241 Loss: 0.5711628599908231\n",
      "In model, X: (500, 4), b: -0.003261635115960605, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 242 Loss: 0.571133890626928\n",
      "In model, X: (500, 4), b: -0.0031221731656874995, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 243 Loss: 0.5711051414218653\n",
      "In model, X: (500, 4), b: -0.0029830061997606996, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 244 Loss: 0.5710766101174103\n",
      "In model, X: (500, 4), b: -0.002844134817458393, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 245 Loss: 0.5710482944860457\n",
      "In model, X: (500, 4), b: -0.002705559590853476, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 246 Loss: 0.5710201923304338\n",
      "In model, X: (500, 4), b: -0.002567281065482364, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 247 Loss: 0.5709923014829015\n",
      "In model, X: (500, 4), b: -0.0024292997609963595, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 248 Loss: 0.5709646198049342\n",
      "In model, X: (500, 4), b: -0.0022916161717960815, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 249 Loss: 0.5709371451866817\n",
      "In model, X: (500, 4), b: -0.00215423076764942, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 250 Loss: 0.570909875546473\n",
      "In model, X: (500, 4), b: -0.002017143994293477, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 251 Loss: 0.5708828088303418\n",
      "In model, X: (500, 4), b: -0.0018803562740209382, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 252 Loss: 0.5708559430115613\n",
      "In model, X: (500, 4), b: -0.001743868006251304, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 253 Loss: 0.570829276090188\n",
      "In model, X: (500, 4), b: -0.0016076795680874051, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 254 Loss: 0.570802806092616\n",
      "In model, X: (500, 4), b: -0.0014717913148576082, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 255 Loss: 0.5707765310711386\n",
      "In model, X: (500, 4), b: -0.001336203580644094, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 256 Loss: 0.5707504491035201\n",
      "In model, X: (500, 4), b: -0.001200916678797609, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 257 Loss: 0.5707245582925755\n",
      "In model, X: (500, 4), b: -0.0010659309024390537, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 258 Loss: 0.5706988567657582\n",
      "In model, X: (500, 4), b: -0.0009312465249482623, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 259 Loss: 0.5706733426747567\n",
      "In model, X: (500, 4), b: -0.0007968638004403416, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 260 Loss: 0.5706480141950988\n",
      "In model, X: (500, 4), b: -0.0006627829642298899, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 261 Loss: 0.5706228695257642\n",
      "In model, X: (500, 4), b: -0.0005290042332834364, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 262 Loss: 0.5705979068888034\n",
      "In model, X: (500, 4), b: -0.0003955278066604248, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 263 Loss: 0.5705731245289651\n",
      "In model, X: (500, 4), b: -0.000262353865943046, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 264 Loss: 0.5705485207133308\n",
      "In model, X: (500, 4), b: -0.00012948257565522446, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 265 Loss: 0.5705240937309569\n",
      "In model, X: (500, 4), b: 3.0859163289487234e-06, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 266 Loss: 0.5704998418925217\n",
      "In model, X: (500, 4), b: 0.00013535147838704387, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 267 Loss: 0.5704757635299822\n",
      "In model, X: (500, 4), b: 0.0002673139947601194, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 268 Loss: 0.5704518569962351\n",
      "In model, X: (500, 4), b: 0.00039897336517426, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 269 Loss: 0.5704281206647859\n",
      "In model, X: (500, 4), b: 0.0005303295044715764, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 270 Loss: 0.5704045529294226\n",
      "In model, X: (500, 4), b: 0.0006613823422504142, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 271 Loss: 0.5703811522038977\n",
      "In model, X: (500, 4), b: 0.0007921318225145164, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 272 Loss: 0.5703579169216147\n",
      "In model, X: (500, 4), b: 0.0009225779033309023, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 273 Loss: 0.5703348455353214\n",
      "In model, X: (500, 4), b: 0.0010527205564962376, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 274 Loss: 0.5703119365168078\n",
      "In model, X: (500, 4), b: 0.0011825597672114583, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 275 Loss: 0.570289188356611\n",
      "In model, X: (500, 4), b: 0.001312095533764439, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 276 Loss: 0.5702665995637259\n",
      "In model, X: (500, 4), b: 0.0014413278672204773, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 277 Loss: 0.570244168665319\n",
      "In model, X: (500, 4), b: 0.001570256791120409, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 278 Loss: 0.5702218942064503\n",
      "In model, X: (500, 4), b: 0.001698882341186125, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 279 Loss: 0.5701997747497983\n",
      "In model, X: (500, 4), b: 0.0018272045650333186, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 280 Loss: 0.5701778088753919\n",
      "In model, X: (500, 4), b: 0.0019552235218912566, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 281 Loss: 0.5701559951803454\n",
      "In model, X: (500, 4), b: 0.002082939282329396, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 282 Loss: 0.5701343322785994\n",
      "In model, X: (500, 4), b: 0.002210351927990663, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 283 Loss: 0.5701128188006667\n",
      "In model, X: (500, 4), b: 0.0023374615513312245, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 284 Loss: 0.5700914533933817\n",
      "In model, X: (500, 4), b: 0.002464268255366567, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 285 Loss: 0.5700702347196563\n",
      "In model, X: (500, 4), b: 0.0025907721534237428, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 286 Loss: 0.5700491614582378\n",
      "In model, X: (500, 4), b: 0.0027169733688996033, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 287 Loss: 0.5700282323034728\n",
      "In model, X: (500, 4), b: 0.002842872035024861, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 288 Loss: 0.5700074459650757\n",
      "In model, X: (500, 4), b: 0.0029684682946338405, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 289 Loss: 0.5699868011678996\n",
      "In model, X: (500, 4), b: 0.003093762299939771, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 290 Loss: 0.569966296651713\n",
      "In model, X: (500, 4), b: 0.0032187542123154555, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 291 Loss: 0.569945931170979\n",
      "In model, X: (500, 4), b: 0.003343444202079213, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 292 Loss: 0.5699257034946413\n",
      "In model, X: (500, 4), b: 0.0034678324482859163, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 293 Loss: 0.5699056124059091\n",
      "In model, X: (500, 4), b: 0.0035919191385230262, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 294 Loss: 0.5698856567020514\n",
      "In model, X: (500, 4), b: 0.0037157044687114813, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 295 Loss: 0.5698658351941899\n",
      "In model, X: (500, 4), b: 0.0038391886429113118, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 296 Loss: 0.5698461467071\n",
      "In model, X: (500, 4), b: 0.003962371873131865, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 297 Loss: 0.5698265900790116\n",
      "In model, X: (500, 4), b: 0.0040852543791465214, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 298 Loss: 0.5698071641614156\n",
      "In model, X: (500, 4), b: 0.0042078363883117885, w: (4, 1)\n",
      "grad: y shape: (500, 1), X shape: (500, 4)\n",
      "gradient shape: (4, 1)\n",
      "y_hat: (500, 1), y: (500, 1)\n",
      "Iter: 299 Loss: 0.5697878678188729\n",
      "In model, X: (500, 4), b: 0.004330118135390656, w: (4, 1)\n",
      "0.912\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = np.random.rand(X_train.shape[1],1)  # assuming X is N-by-n. \n",
    "                                        # if X is n-by-N, use X_train.shape[0]\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "print(w.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "b = 0\n",
    "w, b, loss = train(w, b, X_train, y_train, iter=300, lr=0.1)\n",
    "plt.figure()\n",
    "plt.plot(loss)\n",
    "\n",
    "#training accuracy \n",
    "z = model(w,b,X_train)\n",
    "print(accuracy(np.squeeze(y_train), predict(z)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBm8ESACmrxe"
   },
   "source": [
    "To see how well our model performs, we compute its accuracy on the testing dataset (X_test, y_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt9_Aiw-zqP6",
    "outputId": "7f79e3a5-af48-42d2-dc68-2e0294227c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In model, X: (500, 4), b: 0.004330118135390656, w: (4, 1)\n",
      "0.938\n"
     ]
    }
   ],
   "source": [
    "z = model(w,b,X_test)\n",
    "y_test=np.squeeze(y_test)\n",
    "print(accuracy(y_test, predict(z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u-YnkECyDJXw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef5x5LENm7_s"
   },
   "source": [
    "Now, we look at a real-world dataset. [The Bank Marketing Data Set](https://archive.ics.uci.edu/ml/datasets/Bank+Marketing#) is available at UCI's Machine Learning Repository. Colab can read this dataset directly from [GitHub](https://github.com/madmashup/targeted-marketing-predictive-engine) using pandas package: pd.read_csv. The data is in the DataFrame format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T5vKPwXfYgLV",
    "outputId": "eed99c4f-7064-42d4-a417-8e135935854b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41188, 21)\n",
      "['age', 'job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/madmashup/targeted-marketing-predictive-engine/master/banking.csv'\n",
    "data = pd.read_csv(url)\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG9UWfJ8n2Jr"
   },
   "source": [
    "This dataset is pretty large and cause my machine to crash. I remove some fileds. [This Webpage](https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8) has a good description of this dataset. Note that you are not allowed to use any existing model such as those used in that Webpage for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "pGiNyyIsvUw-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'job', 'marital', 'housing', 'loan', 'duration', 'campaign', 'pdays', 'previous', 'poutcome', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y']\n",
      "(41188, 16)\n"
     ]
    }
   ],
   "source": [
    "cat_vars=['default','education','contact','month','day_of_week',]\n",
    "data=data.drop(cat_vars, axis=1)\n",
    "print(list(data.columns))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVSJRTDeoHNj"
   },
   "source": [
    "Some data columns have k class labels. This is best represented as k columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "du0e-Dhyg2FV",
    "outputId": "09fdef9c-d4ab-4be3-91c7-e04075f6f424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job\n",
      "marital\n",
      "housing\n",
      "loan\n",
      "poutcome\n",
      "(41188, 36)\n",
      "['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate', 'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'y', 'admin.', 'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown', 'divorced', 'married', 'single', 'unknown', 'no', 'unknown', 'yes', 'no', 'unknown', 'yes', 'failure', 'nonexistent', 'success']\n"
     ]
    }
   ],
   "source": [
    "cat_vars=['job','marital','housing','loan','poutcome']\n",
    "for va in cat_vars:\n",
    "    #cat_pre='var'+'_'+var\n",
    "    print(va)\n",
    "    #print(data[va])\n",
    "    cat_list = pd.get_dummies(data[va])\n",
    "    data1=pd.concat([data,cat_list], axis=1)\n",
    "    data=data1.drop(va, axis=1)\n",
    "    #print(list(cat_list.columns))\n",
    "    #print(list(data.columns))\n",
    "    #print(data.shape)\n",
    "\n",
    "print(data.shape)\n",
    "print(list(data.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NazsRFZmpIuD"
   },
   "source": [
    "We now split the data into input data X and the label y. We covert them to numpy and split them into training and testing datasets with 30% for testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u2kDuXGHtBdB",
    "outputId": "00966cf2-0715-4f2f-d500-5aebdfe9c4eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 35)\n",
      "(12357, 35)\n",
      "Index(['age', 'duration', 'campaign', 'pdays', 'previous', 'emp_var_rate',\n",
      "       'cons_price_idx', 'cons_conf_idx', 'euribor3m', 'nr_employed', 'admin.',\n",
      "       'blue-collar', 'entrepreneur', 'housemaid', 'management', 'retired',\n",
      "       'self-employed', 'services', 'student', 'technician', 'unemployed',\n",
      "       'unknown', 'divorced', 'married', 'single', 'unknown', 'no', 'unknown',\n",
      "       'yes', 'no', 'unknown', 'yes', 'failure', 'nonexistent', 'success'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = data.loc[:, data.columns != 'y']\n",
    "y = data.loc[:, data.columns == 'y']\n",
    "columns = X.columns\n",
    "X=X.to_numpy()\n",
    "y=y.to_numpy()\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train1.shape)\n",
    "print(X_test1.shape)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngDOmRz9pxyR"
   },
   "source": [
    "Now, train and test as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 1)\n",
      "(28831, 35)\n",
      "(28831, 1)\n",
      ">> (28831, 35)\n",
      ">> (28831, 35)\n",
      "In model, X: (28831, 35), b: 0, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 0 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.008867885262391177, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 1 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.007735770524782355, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 2 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.006603655787173532, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 3 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005471541049564709, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 4 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.004339426311955884, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 5 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.003207311574347061, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 6 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0020751968367382365, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 7 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0009430820991294124, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 8 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: 0.0001890326384794114, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 9 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.008678852623911765, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 10 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.007546737886302942, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 11 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.00641462314869412, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 12 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005282508411085295, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 13 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.00415039367347647, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 14 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.003018278935867647, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 15 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0018861641982588228, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 16 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0007540494606499991, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 17 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: 0.000377718428080881, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 18 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.008490166834310297, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 19 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.007358052096701472, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 20 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.006225937359092647, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 21 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005093822621483822, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 22 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.003961707883874998, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 23 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0028295931462661733, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 24 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0016974784086573494, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 25 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0005653636710485258, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 26 Loss: 0.6932318593460958\n",
      "In model, X: (28831, 35), b: 0.0005625888800249718, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 27 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.008305296382366205, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 28 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.007173181644757382, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 29 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.006041066907148558, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146295/1126415571.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 30 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.004908952169539733, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 31 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0037768374319309093, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 32 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.002644722694322086, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 33 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.001512607956713262, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 34 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.000380493219104438, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 35 Loss: 0.6931382697239657\n",
      "In model, X: (28831, 35), b: 0.000742256598799901, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 36 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.008125628663591275, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 37 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.006993513925982451, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 38 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005861399188373627, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 39 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.004729284450764802, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 40 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0035971697131559773, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 41 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.002465054975547153, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 42 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0013329402379383285, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 43 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: -0.00020186604696333622, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 44 Loss: 0.6932522109090152\n",
      "In model, X: (28831, 35), b: 0.0009056224203114717, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 45 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.007962262842079706, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 46 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.006830148104470884, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 47 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005698033366862059, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 48 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.004565918629253234, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 49 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0034338038916444107, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 50 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.002301689154035587, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 51 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.001169574416426763, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 52 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: -3.9193923207658286e-05, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 53 Loss: 0.6931497665572696\n",
      "In model, X: (28831, 35), b: 0.001045535988358122, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 54 Loss: 1.2000502137573408\n",
      "In model, X: (28831, 35), b: -0.007822349274033056, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 55 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.00669023453642423, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 56 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005558119798815406, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 57 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.004426005061206581, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 58 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.003293890323597756, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 59 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0021617755859889318, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 60 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: -0.001030007697258052, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 61 Loss: 0.6932318593460958\n",
      "In model, X: (28831, 35), b: 9.794485381544525e-05, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 62 Loss: 0.6930266988657008\n",
      "In model, X: (28831, 35), b: 0.001154766174737542, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 63 Loss: 1.1786221064944586\n",
      "In model, X: (28831, 35), b: -0.007367678818076753, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 64 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.006235564080467927, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 65 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005103449342859103, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 66 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0039713346052502796, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 67 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.002839219867641456, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 68 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0017071051300326322, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 69 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: -0.0005760309390576401, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 70 Loss: 0.6931382697239657\n",
      "In model, X: (28831, 35), b: 0.0005467188788466989, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 71 Loss: 0.6928118447760215\n",
      "In model, X: (28831, 35), b: 0.0013385745915242427, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 72 Loss: 1.1707733178315536\n",
      "In model, X: (28831, 35), b: -0.007057395881478362, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 73 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.005925281143869537, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 74 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.004793166406260713, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 75 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0036610516686518897, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 76 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.002528936931043066, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 77 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: -0.0013971690423121856, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 78 Loss: 0.6932367033154039\n",
      "In model, X: (28831, 35), b: -0.0002681759446048564, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 79 Loss: 0.6932022170106593\n",
      "In model, X: (28831, 35), b: 0.0008434747092052786, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 80 Loss: 0.6939130240841644\n",
      "In model, X: (28831, 35), b: 0.0012744864136254612, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 81 Loss: 0.7886326139483227\n",
      "In model, X: (28831, 35), b: -0.000560187038825364, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 82 Loss: 0.6931431136932739\n",
      "In model, X: (28831, 35), b: 0.0005636033257128071, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 83 Loss: 0.6930794137418449\n",
      "In model, X: (28831, 35), b: 0.001477546968346589, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 84 Loss: 0.9929094905262816\n",
      "In model, X: (28831, 35), b: -0.003980789172164613, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 85 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.002848674434555789, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 86 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0017165596969469655, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 87 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: -0.000585485505971973, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 88 Loss: 0.6931431136932739\n",
      "In model, X: (28831, 35), b: 0.0005383048585661978, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 89 Loss: 0.6926809684131456\n",
      "In model, X: (28831, 35), b: 0.001516889660642189, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 90 Loss: 0.870059497035816\n",
      "In model, X: (28831, 35), b: -0.0018027175560972103, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 91 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: -0.0006716433651222178, w: (35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 92 Loss: 0.6931826425503766\n",
      "In model, X: (28831, 35), b: 0.0004531875460497845, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 93 Loss: 0.6929561502616273\n",
      "In model, X: (28831, 35), b: 0.0014871440512004923, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 94 Loss: 0.7841510655427812\n",
      "In model, X: (28831, 35), b: -0.0002679383715239565, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 95 Loss: 0.693211127846639\n",
      "In model, X: (28831, 35), b: 0.0008530772019906633, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 96 Loss: 0.6926650761455911\n",
      "In model, X: (28831, 35), b: 0.00166127442483437, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 97 Loss: 0.9150536236471833\n",
      "In model, X: (28831, 35), b: -0.002456661827222003, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 98 Loss: 0.6931686891620388\n",
      "In model, X: (28831, 35), b: -0.0013248939384911229, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 99 Loss: 0.6931936861112169\n",
      "In model, X: (28831, 35), b: -0.00019520714302790593, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 100 Loss: 0.6932541450508259\n",
      "In model, X: (28831, 35), b: 0.000925114732730826, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 101 Loss: 0.6926214971995395\n",
      "In model, X: (28831, 35), b: 0.001728399653731673, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 102 Loss: 0.8860794968945105\n",
      "In model, X: (28831, 35), b: -0.001883643893413749, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 103 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: -0.0007525697024387568, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 104 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: 0.00037468915087885275, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 105 Loss: 0.6931026263678647\n",
      "In model, X: (28831, 35), b: 0.0014599792897225094, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 106 Loss: 0.7125596000473632\n",
      "In model, X: (28831, 35), b: 0.0011788347450318614, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 107 Loss: 0.6921034273260763\n",
      "In model, X: (28831, 35), b: 0.0017019730184505415, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 108 Loss: 0.7858289568691749\n",
      "In model, X: (28831, 35), b: -8.235858940032146e-05, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 109 Loss: 0.6932541450508259\n",
      "In model, X: (28831, 35), b: 0.0010379632863584103, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 110 Loss: 0.6926264033048539\n",
      "In model, X: (28831, 35), b: 0.0018495894292201783, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 111 Loss: 0.8792928563548587\n",
      "In model, X: (28831, 35), b: -0.0016330875377239234, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 112 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: -0.0005020133467489309, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 113 Loss: 0.6931874865196846\n",
      "In model, X: (28831, 35), b: 0.0006238581110569034, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 114 Loss: 0.6929003367086699\n",
      "In model, X: (28831, 35), b: 0.0016855625264352435, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 115 Loss: 0.7316650701888217\n",
      "In model, X: (28831, 35), b: 0.0009696029821157278, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 116 Loss: 0.6927861774762939\n",
      "In model, X: (28831, 35), b: 0.0019068902354935665, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 117 Loss: 0.8403865071700111\n",
      "In model, X: (28831, 35), b: -0.0008793691467742432, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 118 Loss: 0.6932235270297029\n",
      "In model, X: (28831, 35), b: 0.0002492771020551417, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 119 Loss: 0.6931890407249585\n",
      "In model, X: (28831, 35), b: 0.0013605809069873326, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 120 Loss: 0.6920860304647836\n",
      "In model, X: (28831, 35), b: 0.001876632253622516, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 121 Loss: 0.776590699350098\n",
      "In model, X: (28831, 35), b: 0.0002697633462610485, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 122 Loss: 0.6932153932963602\n",
      "In model, X: (28831, 35), b: 0.0013817608489491272, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 123 Loss: 0.6916766064037134\n",
      "In model, X: (28831, 35), b: 0.0019319024983870852, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 124 Loss: 0.7861035039730311\n",
      "In model, X: (28831, 35), b: 0.00014259062978482068, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 125 Loss: 0.6932326364487325\n",
      "In model, X: (28831, 35), b: 0.0012632593544214966, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 126 Loss: 0.6924801198314374\n",
      "In model, X: (28831, 35), b: 0.0020654940784337597, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 127 Loss: 0.864383672851259\n",
      "In model, X: (28831, 35), b: -0.0011492440366055088, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 128 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: -1.8863543386404485e-05, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 129 Loss: 0.6931646222953675\n",
      "In model, X: (28831, 35), b: 0.0011045799722738227, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 130 Loss: 0.6922971573307887\n",
      "In model, X: (28831, 35), b: 0.0020764504741208525, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 131 Loss: 0.8106371685071825\n",
      "In model, X: (28831, 35), b: -0.00016288528649658566, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 132 Loss: 0.6931958188360774\n",
      "In model, X: (28831, 35), b: 0.000962292473553361, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 133 Loss: 0.6928706943736864\n",
      "In model, X: (28831, 35), b: 0.002007694991707684, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 134 Loss: 0.7470420828995423\n",
      "In model, X: (28831, 35), b: 0.000975792165942355, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 135 Loss: 0.692885226280766\n",
      "In model, X: (28831, 35), b: 0.002024316323966751, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 136 Loss: 0.7435118114681998\n",
      "In model, X: (28831, 35), b: 0.001067237856183288, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 137 Loss: 0.6928340635314116\n",
      "In model, X: (28831, 35), b: 0.002099806729547208, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 138 Loss: 0.7645709192482683\n",
      "In model, X: (28831, 35), b: 0.0007215562530232237, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 139 Loss: 0.6933320387315078\n",
      "In model, X: (28831, 35), b: 0.0018238420828066918, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 140 Loss: 0.7005382609597977\n",
      "In model, X: (28831, 35), b: 0.0019161069063673049, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 141 Loss: 0.7083924075085059\n",
      "In model, X: (28831, 35), b: 0.0017625613498779046, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 142 Loss: 0.69736384292444\n",
      "In model, X: (28831, 35), b: 0.002012292391434199, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 143 Loss: 0.7211488139760288\n",
      "In model, X: (28831, 35), b: 0.001524954280439284, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 144 Loss: 0.6921226511294082\n",
      "In model, X: (28831, 35), b: 0.0022904507549512017, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 145 Loss: 0.8718207542093286\n",
      "In model, X: (28831, 35), b: -0.0010519162091995032, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 146 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 7.9157981775489e-05, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 147 Loss: 0.6931959456303823\n",
      "In model, X: (28831, 35), b: 0.0012043404331528976, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 148 Loss: 0.6927530244991336\n",
      "In model, X: (28831, 35), b: 0.0022393426494499344, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 149 Loss: 0.7723200582260393\n",
      "In model, X: (28831, 35), b: 0.0007160465720228611, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 150 Loss: 0.6931841258471503\n",
      "In model, X: (28831, 35), b: 0.001827243946728239, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 151 Loss: 0.6948250441483836\n",
      "In model, X: (28831, 35), b: 0.002187272922051634, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 152 Loss: 0.7359902921814343\n",
      "In model, X: (28831, 35), b: 0.0013867672505893135, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 153 Loss: 0.6923469499384028\n",
      "In model, X: (28831, 35), b: 0.002371818063949932, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 154 Loss: 0.8272729906564552\n",
      "In model, X: (28831, 35), b: -0.00017416627393581865, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 155 Loss: 0.6932318593460958\n",
      "In model, X: (28831, 35), b: 0.0009537862771376788, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 156 Loss: 0.693297360838063\n",
      "In model, X: (28831, 35), b: 0.0020560720112433287, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 157 Loss: 0.7021678699485608\n",
      "In model, X: (28831, 35), b: 0.0020912607915471245, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 158 Loss: 0.7047075336724525\n",
      "In model, X: (28831, 35), b: 0.002046356329919838, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 159 Loss: 0.7005407155811213\n",
      "In model, X: (28831, 35), b: 0.0021429967314518165, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 160 Loss: 0.7090499523313251\n",
      "In model, X: (28831, 35), b: 0.00196992007762616, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 161 Loss: 0.6967785541942414\n",
      "In model, X: (28831, 35), b: 0.0022589773407126123, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 162 Loss: 0.7287024374282258\n",
      "In model, X: (28831, 35), b: 0.001610667940751566, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 163 Loss: 0.6921936838651024\n",
      "In model, X: (28831, 35), b: 0.0025305113383689527, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 164 Loss: 0.9216032873206486\n",
      "In model, X: (28831, 35), b: -0.0016969988037728678, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 165 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: -0.0005648840661640441, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 166 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.000566190124810948, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 167 Loss: 0.6931646222953675\n",
      "In model, X: (28831, 35), b: 0.0016896336404711749, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 168 Loss: 0.6922743076279191\n",
      "In model, X: (28831, 35), b: 0.002596990305162686, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 169 Loss: 0.8882305304060858\n",
      "In model, X: (28831, 35), b: -0.0010435376441472603, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 170 Loss: 0.6931901977641324\n",
      "In model, X: (28831, 35), b: 8.788339570567573e-05, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 171 Loss: 0.6932318593460958\n",
      "In model, X: (28831, 35), b: 0.0012158359467791728, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 172 Loss: 0.6932155918794092\n",
      "In model, X: (28831, 35), b: 0.0023104910055700336, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 173 Loss: 0.7080092239566317\n",
      "In model, X: (28831, 35), b: 0.0021670406192909847, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 174 Loss: 0.6977762721390731\n",
      "In model, X: (28831, 35), b: 0.0024089845515106265, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 175 Loss: 0.7213946967903863\n",
      "In model, X: (28831, 35), b: 0.0019160069856726963, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 176 Loss: 0.6915390157901995\n",
      "In model, X: (28831, 35), b: 0.0026688838243398433, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 177 Loss: 0.8610750472622968\n",
      "In model, X: (28831, 35), b: -0.00048382323808953586, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 178 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.0006472509528854566, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 179 Loss: 0.6932041511524701\n",
      "In model, X: (28831, 35), b: 0.001771735015179515, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 180 Loss: 0.6919480400149918\n",
      "In model, X: (28831, 35), b: 0.002725303890852367, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 181 Loss: 0.8497035682939647\n",
      "In model, X: (28831, 35), b: -0.00022232681056305194, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 182 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: 0.0009080536826560523, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 183 Loss: 0.6931979515609381\n",
      "In model, X: (28831, 35), b: 0.0020287224072927284, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 184 Loss: 0.6914548388892997\n",
      "In model, X: (28831, 35), b: 0.002766632042526664, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 185 Loss: 0.8304006666428689\n",
      "In model, X: (28831, 35), b: 0.0001656107003000832, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 186 Loss: 0.6932103507440023\n",
      "In model, X: (28831, 35), b: 0.0012939101002515268, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 187 Loss: 0.6932126820518638\n",
      "In model, X: (28831, 35), b: 0.002400358020891526, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 188 Loss: 0.699581898350042\n",
      "In model, X: (28831, 35), b: 0.0025550566149702193, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 189 Loss: 0.7132121581083951\n",
      "In model, X: (28831, 35), b: 0.002262241452678513, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 190 Loss: 0.6934778514434344\n",
      "In model, X: (28831, 35), b: 0.002696415913905566, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 191 Loss: 0.7474392909162132\n",
      "In model, X: (28831, 35), b: 0.0016586411747136357, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 192 Loss: 0.6928656487369295\n",
      "In model, X: (28831, 35), b: 0.0027203456322798213, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 193 Loss: 0.7462291181552205\n",
      "In model, X: (28831, 35), b: 0.0017071855887805635, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 194 Loss: 0.6927769061676602\n",
      "In model, X: (28831, 35), b: 0.0027647278176314537, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 195 Loss: 0.7542051494806902\n",
      "In model, X: (28831, 35), b: 0.0015941062907770564, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 196 Loss: 0.6930539425434826\n",
      "In model, X: (28831, 35), b: 0.002681280167352925, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 197 Loss: 0.7190915190386166\n",
      "In model, X: (28831, 35), b: 0.0022461206993853178, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 198 Loss: 0.6909720772750901\n",
      "In model, X: (28831, 35), b: 0.0028970383238267872, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 199 Loss: 0.8131319486020679\n",
      "In model, X: (28831, 35), b: 0.0006162385769035535, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 200 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: 0.0017434974302211633, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 201 Loss: 0.6927885282480876\n",
      "In model, X: (28831, 35), b: 0.0028159541608236325, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 202 Loss: 0.7389926831042505\n",
      "In model, X: (28831, 35), b: 0.0019541757460916783, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 203 Loss: 0.6923153571522641\n",
      "In model, X: (28831, 35), b: 0.002972177237088802, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 204 Loss: 0.8164598164403494\n",
      "In model, X: (28831, 35), b: 0.0006269400268017714, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 205 Loss: 0.6932186830603948\n",
      "In model, X: (28831, 35), b: 0.001754545728997325, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 206 Loss: 0.6929937277473053\n",
      "In model, X: (28831, 35), b: 0.00283879532144889, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 207 Loss: 0.7242747433457928\n",
      "In model, X: (28831, 35), b: 0.0022849936073513623, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 208 Loss: 0.6913974994629719\n",
      "In model, X: (28831, 35), b: 0.0030861902492701964, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 209 Loss: 0.8727857980163605\n",
      "In model, X: (28831, 35), b: -0.00026774597123490967, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 210 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.0008633282197400827, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 211 Loss: 0.6932401916624883\n",
      "In model, X: (28831, 35), b: 0.0019905870730576925, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 212 Loss: 0.6925203453644647\n",
      "In model, X: (28831, 35), b: 0.0030377235998632814, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 213 Loss: 0.7697922814624639\n",
      "In model, X: (28831, 35), b: 0.001567348536370042, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 214 Loss: 0.6931442806756054\n",
      "In model, X: (28831, 35), b: 0.002681141175012627, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 215 Loss: 0.6967728589693355\n",
      "In model, X: (28831, 35), b: 0.002977423460605403, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 216 Loss: 0.7306606013072788\n",
      "In model, X: (28831, 35), b: 0.002289040709948195, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 217 Loss: 0.6914381833909955\n",
      "In model, X: (28831, 35), b: 0.0032154740629333485, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 218 Loss: 0.8895721491345884\n",
      "In model, X: (28831, 35), b: -0.0004421591602034715, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 219 Loss: 0.6931901977641324\n",
      "In model, X: (28831, 35), b: 0.0006892618796494646, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 220 Loss: 0.6932235270297029\n",
      "In model, X: (28831, 35), b: 0.0018179081284788495, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 221 Loss: 0.6931309144891736\n",
      "In model, X: (28831, 35), b: 0.0029167253458873468, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 222 Loss: 0.7047378508122688\n",
      "In model, X: (28831, 35), b: 0.0028730302144839605, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 223 Loss: 0.7005416104112961\n",
      "In model, X: (28831, 35), b: 0.0029742376832318793, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 224 Loss: 0.7100188831744376\n",
      "In model, X: (28831, 35), b: 0.0027749668779971383, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 225 Loss: 0.6962105252705575\n",
      "In model, X: (28831, 35), b: 0.003102022493787819, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 226 Loss: 0.7365811580866768\n",
      "In model, X: (28831, 35), b: 0.0022925247262692485, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 227 Loss: 0.6921532003536203\n",
      "In model, X: (28831, 35), b: 0.0032907406174451583, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 228 Loss: 0.8493838595852187\n",
      "In model, X: (28831, 35), b: 0.0003510964677810299, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 229 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.0014821706587560223, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 230 Loss: 0.693186130897461\n",
      "In model, X: (28831, 35), b: 0.002605267325538305, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 231 Loss: 0.6906429564351528\n",
      "In model, X: (28831, 35), b: 0.0033235578792723715, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 232 Loss: 0.8226315729728895\n",
      "In model, X: (28831, 35), b: 0.0008697830030172899, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 233 Loss: 0.6932367033154039\n",
      "In model, X: (28831, 35), b: 0.001998776100724619, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 234 Loss: 0.6930865402884668\n",
      "In model, X: (28831, 35), b: 0.0030955122523508107, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 235 Loss: 0.7081950389822844\n",
      "In model, X: (28831, 35), b: 0.002949479836431711, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 236 Loss: 0.6974899500470849\n",
      "In model, X: (28831, 35), b: 0.003212826923294933, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 237 Loss: 0.72845853856058\n",
      "In model, X: (28831, 35), b: 0.002571822118920691, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 238 Loss: 0.6911917551787857\n",
      "In model, X: (28831, 35), b: 0.0034625646331932587, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 239 Loss: 0.9100290032191217\n",
      "In model, X: (28831, 35), b: -0.0005496574979021204, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 240 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: 0.0005824572397067031, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 241 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.0017135314306816953, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 242 Loss: 0.69314175807105\n",
      "In model, X: (28831, 35), b: 0.002834547004196316, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 243 Loss: 0.691981021641951\n",
      "In model, X: (28831, 35), b: 0.0033992796196766575, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 244 Loss: 0.7699063905989572\n",
      "In model, X: (28831, 35), b: 0.0019275908841441443, w: (35, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 245 Loss: 0.693173731714397\n",
      "In model, X: (28831, 35), b: 0.003043056875611662, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 246 Loss: 0.6966701544341865\n",
      "In model, X: (28831, 35), b: 0.003353367509837399, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 247 Loss: 0.7347416652447666\n",
      "In model, X: (28831, 35), b: 0.0025791592923614043, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 248 Loss: 0.6917317313702034\n",
      "In model, X: (28831, 35), b: 0.003556232581390713, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 249 Loss: 0.8630274063293328\n",
      "In model, X: (28831, 35), b: 0.0003753015741055033, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 250 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.0015063757650804952, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 251 Loss: 0.6932006628053856\n",
      "In model, X: (28831, 35), b: 0.002632594071764273, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 252 Loss: 0.6916741825679908\n",
      "In model, X: (28831, 35), b: 0.003607239563539316, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 253 Loss: 0.8451522256824077\n",
      "In model, X: (28831, 35), b: 0.0007473616065576268, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 254 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.0018784357975326189, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 255 Loss: 0.69314175807105\n",
      "In model, X: (28831, 35), b: 0.002999451371047239, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 256 Loss: 0.6926377074368081\n",
      "In model, X: (28831, 35), b: 0.0035502469579295425, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 257 Loss: 0.7610896918590533\n",
      "In model, X: (28831, 35), b: 0.0022525011590132545, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 258 Loss: 0.6930844075419884\n",
      "In model, X: (28831, 35), b: 0.0033537463464850723, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 259 Loss: 0.7039848856526237\n",
      "In model, X: (28831, 35), b: 0.0033294670666905316, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 260 Loss: 0.7013012282832481\n",
      "In model, X: (28831, 35), b: 0.0033962959981855907, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 261 Loss: 0.7075747868620301\n",
      "In model, X: (28831, 35), b: 0.0032676685200300555, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 262 Loss: 0.6977626699317415\n",
      "In model, X: (28831, 35), b: 0.0035143173173901292, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 263 Loss: 0.7279830261110437\n",
      "In model, X: (28831, 35), b: 0.0028831644827359555, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 264 Loss: 0.6909048551884177\n",
      "In model, X: (28831, 35), b: 0.003759076811742323, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 265 Loss: 0.9083831364791154\n",
      "In model, X: (28831, 35), b: -0.00022481794461950676, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 266 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: 0.000907296792989317, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 267 Loss: 0.6931770214784314\n",
      "In model, X: (28831, 35), b: 0.002038370983964309, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 268 Loss: 0.69314175807105\n",
      "In model, X: (28831, 35), b: 0.003159386557478929, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 269 Loss: 0.6934880782041754\n",
      "In model, X: (28831, 35), b: 0.0036757604206975126, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 270 Loss: 0.7571605732522457\n",
      "In model, X: (28831, 35), b: 0.0024490502598125655, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 271 Loss: 0.693065039699241\n",
      "In model, X: (28831, 35), b: 0.0035461331000779567, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 272 Loss: 0.710704822881358\n",
      "In model, X: (28831, 35), b: 0.0033245429656359677, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 273 Loss: 0.6952752554007285\n",
      "In model, X: (28831, 35), b: 0.003691854494522485, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 274 Loss: 0.748157849312979\n",
      "In model, X: (28831, 35), b: 0.0026459365237320774, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 275 Loss: 0.6928592535105789\n",
      "In model, X: (28831, 35), b: 0.003721168042652381, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 276 Loss: 0.7493323451921378\n",
      "In model, X: (28831, 35), b: 0.002651757075704138, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 277 Loss: 0.6929660195537305\n",
      "In model, X: (28831, 35), b: 0.003732538179377267, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 278 Loss: 0.742819481191203\n",
      "In model, X: (28831, 35), b: 0.0027963915503945096, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 279 Loss: 0.6924586167022742\n",
      "In model, X: (28831, 35), b: 0.0038450673221422445, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 280 Loss: 0.7954356389797167\n",
      "In model, X: (28831, 35), b: 0.0018957701861104898, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 281 Loss: 0.6932270153767874\n",
      "In model, X: (28831, 35), b: 0.003022682190550156, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 282 Loss: 0.6913991715713748\n",
      "In model, X: (28831, 35), b: 0.0039755470605111615, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 283 Loss: 0.9008831644016576\n",
      "In model, X: (28831, 35), b: 0.0001226380863582075, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 284 Loss: 0.6931471805599453\n",
      "In model, X: (28831, 35), b: 0.0012547528239670316, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 285 Loss: 0.6931506689070297\n",
      "In model, X: (28831, 35), b: 0.002385133317186136, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 286 Loss: 0.6931667550202281\n",
      "In model, X: (28831, 35), b: 0.0035040677974330922, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 287 Loss: 0.695166087485633\n",
      "In model, X: (28831, 35), b: 0.0038876826566285358, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 288 Loss: 0.7507350618644575\n",
      "In model, X: (28831, 35), b: 0.0027896728603381974, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 289 Loss: 0.6929361786352445\n",
      "In model, X: (28831, 35), b: 0.0038714945106451586, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 290 Loss: 0.7339386292642754\n",
      "In model, X: (28831, 35), b: 0.003119116463183573, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 291 Loss: 0.6914339380876361\n",
      "In model, X: (28831, 35), b: 0.004081961714834411, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 292 Loss: 0.8816803962165655\n",
      "In model, X: (28831, 35), b: 0.0005785568476763171, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 293 Loss: 0.6931901977641324\n",
      "In model, X: (28831, 35), b: 0.001709977887529253, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 294 Loss: 0.6932103507440021\n",
      "In model, X: (28831, 35), b: 0.0028382772874806944, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 295 Loss: 0.69296388682887\n",
      "In model, X: (28831, 35), b: 0.0039235674265670935, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 296 Loss: 0.7232298578197941\n",
      "In model, X: (28831, 35), b: 0.003399277025238394, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 297 Loss: 0.6904591600056894\n",
      "In model, X: (28831, 35), b: 0.004078630252927932, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 298 Loss: 0.7913695736896061\n",
      "In model, X: (28831, 35), b: 0.0022032044544518883, w: (35, 1)\n",
      "grad: y shape: (28831, 1), X shape: (28831, 35)\n",
      "gradient shape: (35, 1)\n",
      "y_hat: (28831, 1), y: (28831, 1)\n",
      "Iter: 299 Loss: 0.6932089951217781\n",
      "In model, X: (28831, 35), b: 0.003328729063379778, w: (35, 1)\n",
      "0.8989282369671534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w1 = np.random.rand(X_train1.shape[1],1)  # assuming X is N-by-n. \n",
    "                                        # if X is n-by-N, use X_train.shape[0]\n",
    "y_train1 = y_train1.reshape(-1,1)\n",
    "y_test1 = y_test1.reshape(-1,1)\n",
    "print(w1.shape)\n",
    "print(X_train1.shape)\n",
    "print(y_train1.shape)\n",
    "b1 = 0\n",
    "w1, b1, loss1 = train(w1, b1, X_train1, y_train1, iter=300, lr=0.01)\n",
    "plt.figure()\n",
    "plt.plot(loss1)\n",
    "\n",
    "#training accuracy \n",
    "z1 = model(w1,b1,X_train1)\n",
    "print(accuracy(np.squeeze(y_train1), predict(z1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In model, X: (12357, 35), b: 0.003328729063379778, w: (35, 1)\n",
      "0.9022416444120741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146295/1126415571.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-t))\n"
     ]
    }
   ],
   "source": [
    "z1 = model(w1,b1,X_test1)\n",
    "y_test1=np.squeeze(y_test1)\n",
    "print(accuracy(y_test1, predict(z1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
